{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c6b76f-3d83-479e-a35e-3579dd6a507b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "#Packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import pygris\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80c61c-eaa6-458b-a891-52919c4bf4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/FimaNfipClaims.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979a1f2-d151-47cf-bc2f-48d667967e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2000 = df[df['yearOfLoss']>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfb43d-67c5-4a5c-86d6-efd270904e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zipcode list\n",
    "\n",
    "list_zipcode = df_2000['reportedZipCode'].dropna().drop_duplicates().astype(int).astype(str).tolist()\n",
    "\n",
    "# add preceding 0 to make 4-digit zip codes into 5-digit\n",
    "list_zipcode = [zipcode.zfill(5) for zipcode in list_zipcode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29413f-7327-4d96-808e-8d05de9c7eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CensusBG list\n",
    "\n",
    "list_censusBG = df['censusBlockGroupFips'].dropna().drop_duplicates().tolist()\n",
    "\n",
    "list_censusBG = [str(int(float(i))) for i in list_censusBG]\n",
    "\n",
    "# add preceding 0 to make 4-digit zip codes into 5-digit\n",
    "list_censusBG = [censusBG.zfill(12) for censusBG in list_censusBG]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd09923-9cf3-44d3-864d-bd6ec79c4a1f",
   "metadata": {},
   "source": [
    "## BlockGroup shapefile analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bed775-d9f7-4355-bd48-fdae4939f4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 25000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 400000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/BG_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "merged_gdf = pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055294c-7485-49e1-9046-42f36ac244b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18aa04e-a9d1-470f-92fe-ac2b116f877e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = merged_gdf['GEOID'].value_counts().reset_index()\n",
    "df_test.columns = ['GEOID', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33468d0f-de52-4ddb-b923-35260afe0b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[df_test['count'] >= 6].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af63c20-f80f-45df-9eea-a5f62fd93d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddc682-43d8-4523-8264-e58871eca44b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_censusBG_3 = merged_gdf['GEOID'].dropna().drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ee41b-ab9a-4000-82d4-ecbff3fea40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CensusBG list for NC\n",
    "\n",
    "list_censusBG = df['censusBlockGroupFips'].dropna().drop_duplicates().tolist()\n",
    "\n",
    "list_censusBG = [str(int(float(i))) for i in list_censusBG]\n",
    "\n",
    "# add preceding 0 to make 11-digit BG ids into 12-digits\n",
    "list_censusBG = [censusBG.zfill(12) for censusBG in list_censusBG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e668ce-887d-46a6-8760-904c79cb6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both lists to sets\n",
    "set_bg = set(list_censusBG)\n",
    "set_bg_2 = set(list_censusBG_3)\n",
    "\n",
    "# Find the intersection of the two sets\n",
    "common_bg = set_bg.intersection(set_bg_2)\n",
    "\n",
    "# Print the number of common zip codes\n",
    "print(\"Number of common BG:\", len(common_bg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba564fab-a918-4982-8546-c8c1321ac43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(common_bg)/len(list_censusBG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626b13a-a828-4079-87d1-034b858bb62a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have defined list_censusBG and common_bg\n",
    "list_BG_not_found = set(list_censusBG) - common_bg\n",
    "list_BG_not_found = list(list_BG_not_found)\n",
    "\n",
    "print(\"CensusBG values not in common:\", list_BG_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249647fa-141d-485d-840e-995fe6939b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_BG_not_found = df[['censusBlockGroupFips', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad661c1-536b-4455-b9e7-920a472578c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned = df_BG_not_found.dropna(subset=['censusBlockGroupFips'])\n",
    "\n",
    "# Now you can proceed with the remaining operations on df_cleaned\n",
    "df_cleaned['censusBlockGroupFips'] = [str(int(float(i))) for i in df_cleaned['censusBlockGroupFips']]\n",
    "df_cleaned['censusBlockGroupFips'] = [censusBG.zfill(12) for censusBG in df_cleaned['censusBlockGroupFips']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16c5aa-7089-45ce-a5fb-602639bed0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned[df_cleaned['censusBlockGroupFips'].isin(list_BG_not_found)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbea23-07cb-40a3-9b61-5041e776b714",
   "metadata": {},
   "source": [
    "## Zipcode shapefile analysis (until 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046ad13-c7d0-4795-917e-97eff3b0cb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 25000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 100000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/zipcode_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "    \n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "merged_gdf_zipcode = pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6b620-9df6-4b65-8850-0e9017f02451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_gdf_zipcode.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf143440-611d-4c0d-9248-6d32c972a7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_gdf_zipcode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc8bcec-40a9-4561-b6ac-7c2f245db114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_zip = merged_gdf_zipcode['ZIPcode'].dropna().drop_duplicates().astype(int).astype(str).tolist()\n",
    "\n",
    "list_zip = [zipcode.zfill(5) for zipcode in list_zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eccc5f-670e-4973-ab87-ea55fc79bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_zip_1 = list(set(list_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7200b66-b9a7-4d5b-95ed-f09aef7be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_zipcode = set(list_zipcode)\n",
    "set_zipcode_3 = set(list_zip_1)\n",
    "\n",
    "# Find the intersection of the two sets\n",
    "common_zipcodes = set_zipcode.intersection(set_zipcode_3)\n",
    "\n",
    "# Print the number of common zip codes\n",
    "print(\"Number of common zip codes:\", len(common_zipcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070fe5fb-fb29-4bb3-aae2-9d2d6f070f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(set_zipcode_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a09d20-35f6-4d92-9383-885a91b2e5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(set_zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73867e95-a172-45b2-8020-035a4aac3714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1-len(common_zipcodes)/len(set_zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4efcec-f61e-491f-9445-3adc0e57c6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the difference between set_zipcode and common_zipcodes\n",
    "zipcodes_not_in_common = set_zipcode - common_zipcodes\n",
    "\n",
    "# Convert the result back to a list\n",
    "list_zipcodes_not_in_common = list(zipcodes_not_in_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e8a06-ebe4-4073-96e1-607088a0541e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the list of zipcodes to a set for faster membership checking\n",
    "set_zipcodes_not_in_common = set(list_zipcodes_not_in_common)\n",
    "\n",
    "df_test = df_2000[['reportedZipCode', 'yearOfLoss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fe537-ca49-4025-a813-2819ca6be721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['reportedZipCode'] = df_test['reportedZipCode'].dropna().astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c136fa0-e704-460d-a41c-7722338d9473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_list = df_test[df_test['reportedZipCode'].isin(zipcodes_not_in_common)]['yearOfLoss'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50aa6ed-942e-43ae-a9dc-83548b367e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc9388-a578-4ba3-88e0-0195640734f2",
   "metadata": {},
   "source": [
    "## BG Shapefile Analysis.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e15-b291-4594-81a9-a2ca6c4093c5",
   "metadata": {},
   "source": [
    "### BG Shapefile Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4519fa-52c7-44f9-a035-48de9a2ea252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 25000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 400000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/BG_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "BG_df_old = pd.concat(gdf_list, ignore_index=True)\n",
    "\n",
    "BG_df_old['year'] = BG_df_old['year'].replace({2012: 2010, 2021: 2020})\n",
    "BG_df_old = BG_df_old.drop_duplicates(subset=['GEOID', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680bea34-7912-4f80-ba4b-b607d4d479c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG_df_old.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b08f2e64-a7ef-411e-be05-6cf47b4ed0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35615"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG_df_old[BG_df_old['year']==2000].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8698476e-1ccf-4c08-bcd1-868a1ed4a15e",
   "metadata": {},
   "source": [
    "### BF Shapefile New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa842f58-9842-4e4e-84ab-fcb47b4d1b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 40000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 320000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/BG_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "BG_df_new = pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3948df8b-aa47-4084-9c88-e512194b061c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG_df_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d629df-641e-4fc8-b547-8d2d1048bc97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73354"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG_df_new[BG_df_new['year']==2000].shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
