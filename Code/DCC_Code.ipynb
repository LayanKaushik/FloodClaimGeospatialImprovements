{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbec566-6bba-428c-b77f-c094322eec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import pygris\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f12f0-e4de-4e56-b24c-70090ce149f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/FimaNfipClaims.parquet.gzip\")\n",
    "df_BGstate = df[['censusBlockGroupFips', 'state']].dropna().drop_duplicates()\n",
    "df_BGstate['censusBlockGroupFips'] = [str(int(float(i))) for i in df_BGstate['censusBlockGroupFips']]\n",
    "df_BGstate['censusBlockGroupFips'] = [censusBG.zfill(12) for censusBG in df_BGstate['censusBlockGroupFips']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239af0db-bf58-46f7-9c6f-ab7ada25c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the parquet file\n",
    "df_read = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/lat_long_geometry.parquet.gzip\")\n",
    "\n",
    "# Convert the WKT strings back to geometries\n",
    "lat_long_df = gpd.GeoDataFrame(df_read, geometry=df_read['geometry'].apply(lambda x: shapely.wkt.loads(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48fd71-6794-4af0-bb5f-c31b8feceb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 25000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 400000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/BG_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "BG_df = pd.concat(gdf_list, ignore_index=True)\n",
    "\n",
    "BG_df = BG_df.drop_duplicates(subset=['GEOID', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1862eec-0ece-4e3a-ba53-ea5b5b944264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of df_BGstate to 'censusBlockGroupFips'\n",
    "df_BGstate.drop_duplicates(subset='censusBlockGroupFips', inplace=True)\n",
    "df_BGstate.set_index('censusBlockGroupFips', inplace=True)\n",
    "\n",
    "# Map the 'state' values to 'GEOID' in BG_df\n",
    "BG_df['state'] = BG_df['GEOID'].map(df_BGstate['state'])\n",
    "\n",
    "# Reset the index of df_BGstate if needed\n",
    "df_BGstate.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bc363-ecd0-4c53-9a36-6a00a3be210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_df_yearwise = {}\n",
    "\n",
    "# Iterate through unique years and create separate DataFrames\n",
    "for year in BG_df['year'].unique():\n",
    "    BG_df_yearwise[year] = BG_df[BG_df['year'] == year].copy()\n",
    "\n",
    "BG_df_2021 = BG_df_yearwise[2021]\n",
    "BG_df_2012 = BG_df_yearwise[2012]\n",
    "BG_df_2010 = BG_df_yearwise[2010]\n",
    "BG_df_2000 = BG_df_yearwise[2000]\n",
    "BG_df_1990 = BG_df_yearwise[1990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd1812-b6df-4b4d-bc2f-53d6c9a7d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df_2021 = gpd.GeoDataFrame(columns=['geographic_unit_id', 'BG_id', 'latitude', 'longitude', 'geometry', 'year', 'state'])\n",
    "\n",
    "# Iterate through each row in BG_df_2021 and each row in lat_long_df to find intersections\n",
    "for idx_bg, row_bg in BG_df_2021.iterrows():\n",
    "    year = row_bg['year']\n",
    "    bg_id = row_bg['GEOID']\n",
    "    bg_geometry = row_bg['geometry']\n",
    "    state = row_bg['state']\n",
    "    \n",
    "    for idx_lat_long, row_lat_long in lat_long_df.iterrows():\n",
    "        \n",
    "        lat_long_geometry = row_lat_long['geometry']\n",
    "        lat = row_lat_long['latitude']\n",
    "        long = row_lat_long['longitude']\n",
    "        # Compute intersection geometry\n",
    "\n",
    "        intersection_geometry = bg_geometry.intersection(lat_long_geometry)\n",
    "            \n",
    "        # Check if the intersection result is valid\n",
    "        if not intersection_geometry.is_empty:\n",
    "            # Create a unique ID for the intersection using the year and indices\n",
    "            geographic_unit_id = f\"{year}_{bg_id}_{lat}_{long}\"\n",
    "\n",
    "            # Append intersection information to a list\n",
    "            new_unit_df_2021 = pd.concat([new_unit_df_2021, pd.DataFrame({\n",
    "                'geographic_unit_id': [geographic_unit_id],\n",
    "                'BG_id': [bg_id],\n",
    "                'latitude': [lat],\n",
    "                'longitude': [long],\n",
    "                'geometry': [intersection_geometry],\n",
    "                'year': [year],\n",
    "                'state': [state]\n",
    "            })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6e575-45b7-4a21-beaf-8219536a9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df_2012 = gpd.GeoDataFrame(columns=['geographic_unit_id', 'BG_id', 'latitude', 'longitude', 'geometry', 'year', 'state'])\n",
    "\n",
    "# Iterate through each row in BG_df_2012 and each row in lat_long_df to find intersections\n",
    "for idx_bg, row_bg in BG_df_2012.iterrows():\n",
    "    year = row_bg['year']\n",
    "    bg_id = row_bg['GEOID']\n",
    "    bg_geometry = row_bg['geometry']\n",
    "    state = row_bg['state']\n",
    "    \n",
    "    for idx_lat_long, row_lat_long in lat_long_df.iterrows():\n",
    "        \n",
    "        lat_long_geometry = row_lat_long['geometry']\n",
    "        lat = row_lat_long['latitude']\n",
    "        long = row_lat_long['longitude']\n",
    "        # Compute intersection geometry\n",
    "\n",
    "        intersection_geometry = bg_geometry.intersection(lat_long_geometry)\n",
    "            \n",
    "        # Check if the intersection result is valid\n",
    "        if not intersection_geometry.is_empty:\n",
    "            # Create a unique ID for the intersection using the year and indices\n",
    "            geographic_unit_id = f\"{year}_{bg_id}_{lat}_{long}\"\n",
    "\n",
    "            # Append intersection information to a list\n",
    "            new_unit_df_2012 = pd.concat([new_unit_df_2012, pd.DataFrame({\n",
    "                'geographic_unit_id': [geographic_unit_id],\n",
    "                'BG_id': [bg_id],\n",
    "                'latitude': [lat],\n",
    "                'longitude': [long],\n",
    "                'geometry': [intersection_geometry],\n",
    "                'year': [year],\n",
    "                'state': [state]\n",
    "            })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f163c-59fd-4c48-887c-4a444a5dc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df_2010 = gpd.GeoDataFrame(columns=['geographic_unit_id', 'BG_id', 'latitude', 'longitude', 'geometry', 'year', 'state'])\n",
    "\n",
    "# Iterate through each row in BG_df_2010 and each row in lat_long_df to find intersections\n",
    "for idx_bg, row_bg in BG_df_2010.iterrows():\n",
    "    year = row_bg['year']\n",
    "    bg_id = row_bg['GEOID']\n",
    "    bg_geometry = row_bg['geometry']\n",
    "    state = row_bg['state']\n",
    "    \n",
    "    for idx_lat_long, row_lat_long in lat_long_df.iterrows():\n",
    "        \n",
    "        lat_long_geometry = row_lat_long['geometry']\n",
    "        lat = row_lat_long['latitude']\n",
    "        long = row_lat_long['longitude']\n",
    "        # Compute intersection geometry\n",
    "\n",
    "        intersection_geometry = bg_geometry.intersection(lat_long_geometry)\n",
    "            \n",
    "        # Check if the intersection result is valid\n",
    "        if not intersection_geometry.is_empty:\n",
    "            # Create a unique ID for the intersection using the year and indices\n",
    "            geographic_unit_id = f\"{year}_{bg_id}_{lat}_{long}\"\n",
    "\n",
    "            # Append intersection information to a list\n",
    "            new_unit_df_2010 = pd.concat([new_unit_df_2010, pd.DataFrame({\n",
    "                'geographic_unit_id': [geographic_unit_id],\n",
    "                'BG_id': [bg_id],\n",
    "                'latitude': [lat],\n",
    "                'longitude': [long],\n",
    "                'geometry': [intersection_geometry],\n",
    "                'year': [year],\n",
    "                'state': [state]\n",
    "            })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819445c7-bc51-4261-81a3-e1001a1c82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df_2000 = gpd.GeoDataFrame(columns=['geographic_unit_id', 'BG_id', 'latitude', 'longitude', 'geometry', 'year', 'state'])\n",
    "\n",
    "# Iterate through each row in BG_df_2000 and each row in lat_long_df to find intersections\n",
    "for idx_bg, row_bg in BG_df_2000.iterrows():\n",
    "    year = row_bg['year']\n",
    "    bg_id = row_bg['GEOID']\n",
    "    bg_geometry = row_bg['geometry']\n",
    "    state = row_bg['state']\n",
    "    \n",
    "    for idx_lat_long, row_lat_long in lat_long_df.iterrows():\n",
    "        \n",
    "        lat_long_geometry = row_lat_long['geometry']\n",
    "        lat = row_lat_long['latitude']\n",
    "        long = row_lat_long['longitude']\n",
    "        # Compute intersection geometry\n",
    "\n",
    "        intersection_geometry = bg_geometry.intersection(lat_long_geometry)\n",
    "            \n",
    "        # Check if the intersection result is valid\n",
    "        if not intersection_geometry.is_empty:\n",
    "            # Create a unique ID for the intersection using the year and indices\n",
    "            geographic_unit_id = f\"{year}_{bg_id}_{lat}_{long}\"\n",
    "\n",
    "            # Append intersection information to a list\n",
    "            new_unit_df_2000 = pd.concat([new_unit_df_2000, pd.DataFrame({\n",
    "                'geographic_unit_id': [geographic_unit_id],\n",
    "                'BG_id': [bg_id],\n",
    "                'latitude': [lat],\n",
    "                'longitude': [long],\n",
    "                'geometry': [intersection_geometry],\n",
    "                'year': [year],\n",
    "                'state': [state]\n",
    "            })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ddd423-2999-48ee-8fd4-bc918017f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df_1990 = gpd.GeoDataFrame(columns=['geographic_unit_id', 'BG_id', 'latitude', 'longitude', 'geometry', 'year', 'state'])\n",
    "\n",
    "# Iterate through each row in BG_df_1990 and each row in lat_long_df to find intersections\n",
    "for idx_bg, row_bg in BG_df_1990.iterrows():\n",
    "    year = row_bg['year']\n",
    "    bg_id = row_bg['GEOID']\n",
    "    bg_geometry = row_bg['geometry']\n",
    "    state = row_bg['state']\n",
    "    \n",
    "    for idx_lat_long, row_lat_long in lat_long_df.iterrows():\n",
    "        \n",
    "        lat_long_geometry = row_lat_long['geometry']\n",
    "        lat = row_lat_long['latitude']\n",
    "        long = row_lat_long['longitude']\n",
    "        # Compute intersection geometry\n",
    "\n",
    "        intersection_geometry = bg_geometry.intersection(lat_long_geometry)\n",
    "            \n",
    "        # Check if the intersection result is valid\n",
    "        if not intersection_geometry.is_empty:\n",
    "            # Create a unique ID for the intersection using the year and indices\n",
    "            geographic_unit_id = f\"{year}_{bg_id}_{lat}_{long}\"\n",
    "\n",
    "            # Append intersection information to a list\n",
    "            new_unit_df_1990 = pd.concat([new_unit_df_1990, pd.DataFrame({\n",
    "                'geographic_unit_id': [geographic_unit_id],\n",
    "                'BG_id': [bg_id],\n",
    "                'latitude': [lat],\n",
    "                'longitude': [long],\n",
    "                'geometry': [intersection_geometry],\n",
    "                'year': [year],\n",
    "                'state': [state]\n",
    "            })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158656ea-ddb0-48a4-988c-9a51adaa3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unit_df = pd.concat([new_unit_df_2021, new_unit_df_2012, new_unit_df_2010, new_unit_df_2000, new_unit_df_1990], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6eeea-9a58-4db9-ae92-67a154d6e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unit_df['geometry'] = new_unit_df['geometry'].apply(lambda geom: geom.wkt)\n",
    "new_unit_df.to_parquet(f\"new_unit_geometry.parquet.gzip\", compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
