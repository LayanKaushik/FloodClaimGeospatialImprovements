{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e6a33fa-936f-4abe-98dd-197343e523df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "#Packages\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import pygris\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3276995e-b191-495a-a279-935ed0fe65b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/FimaNfipClaims.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015de0f2-4349-4203-9875-5552c6594a26",
   "metadata": {},
   "source": [
    "## First Dataset [Use Zip Code]\n",
    "## No geographic values missing, no shapefiles missing, post 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "259aa2a8-afb3-47d8-bcfd-32b053e0e958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df[['state', 'reportedZipCode', 'countyCode', 'censusTract', 'censusBlockGroupFips', 'latitude', 'longitude', 'yearOfLoss']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9f82936-6fe6-467d-b27e-d0b5e43104ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df_geographic_unique.dropna(subset=['latitude', 'censusBlockGroupFips', 'reportedZipCode', 'countyCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7262b4c-9f66-487c-9ac1-8eb07cb35388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>reportedZipCode</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>censusTract</th>\n",
       "      <th>censusBlockGroupFips</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>yearOfLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>92056.0</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>6.073019e+09</td>\n",
       "      <td>6.073019e+10</td>\n",
       "      <td>33.2</td>\n",
       "      <td>-117.3</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA</td>\n",
       "      <td>70131.0</td>\n",
       "      <td>22071.0</td>\n",
       "      <td>2.207100e+10</td>\n",
       "      <td>2.207100e+11</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FL</td>\n",
       "      <td>32566.0</td>\n",
       "      <td>12113.0</td>\n",
       "      <td>1.211301e+10</td>\n",
       "      <td>1.211301e+11</td>\n",
       "      <td>30.4</td>\n",
       "      <td>-86.9</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SC</td>\n",
       "      <td>29902.0</td>\n",
       "      <td>45013.0</td>\n",
       "      <td>4.501300e+10</td>\n",
       "      <td>4.501300e+11</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FL</td>\n",
       "      <td>32940.0</td>\n",
       "      <td>12009.0</td>\n",
       "      <td>1.200906e+10</td>\n",
       "      <td>1.200906e+11</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  reportedZipCode  countyCode   censusTract  censusBlockGroupFips  \\\n",
       "0    CA          92056.0      6073.0  6.073019e+09          6.073019e+10   \n",
       "1    LA          70131.0     22071.0  2.207100e+10          2.207100e+11   \n",
       "2    FL          32566.0     12113.0  1.211301e+10          1.211301e+11   \n",
       "3    SC          29902.0     45013.0  4.501300e+10          4.501300e+11   \n",
       "4    FL          32940.0     12009.0  1.200906e+10          1.200906e+11   \n",
       "\n",
       "   latitude  longitude  yearOfLoss  \n",
       "0      33.2     -117.3        1998  \n",
       "1      29.9      -90.0        2005  \n",
       "2      30.4      -86.9        1998  \n",
       "3      32.4      -80.7        1994  \n",
       "4      28.3      -80.7        1996  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geographic_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fefcacd-91e5-4c57-90ae-a5b478ae7a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(df_geographic_unique['state'].isna()))\n",
    "print(sum(df_geographic_unique['reportedZipCode'].isna()))\n",
    "print(sum(df_geographic_unique['countyCode'].isna()))\n",
    "print(sum(df_geographic_unique['censusTract'].isna()))\n",
    "print(sum(df_geographic_unique['censusBlockGroupFips'].isna()))\n",
    "print(sum(df_geographic_unique['latitude'].isna()))\n",
    "print(sum(df_geographic_unique['yearOfLoss'].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "472bcc5a-7601-45f0-a129-d3511ab53afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique['reportedZipCode'] = df_geographic_unique['reportedZipCode'].dropna().astype(int).astype(str)\n",
    "df_geographic_unique['reportedZipCode'] = [zipcode.zfill(5) for zipcode in df_geographic_unique['reportedZipCode']]\n",
    "\n",
    "df_geographic_unique['censusBlockGroupFips'] = [str(int(float(i))) for i in df_geographic_unique['censusBlockGroupFips']]\n",
    "df_geographic_unique['censusBlockGroupFips'] = [censusBG.zfill(12) for censusBG in df_geographic_unique['censusBlockGroupFips']]\n",
    "\n",
    "df_geographic_unique['countyCode'] = [str(int(float(i))) for i in df_geographic_unique['countyCode']]\n",
    "df_geographic_unique['countyCode'] = [censusBG.zfill(5) for censusBG in df_geographic_unique['countyCode']]\n",
    "\n",
    "df_geographic_unique['censusTract'] = [str(int(float(i))) for i in df_geographic_unique['censusTract']]\n",
    "df_geographic_unique['censusTract'] = [censusBG.zfill(11) for censusBG in df_geographic_unique['censusTract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2d561ce-6213-4ead-a082-f8f676a12a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define bins and labels for yearOfLoss_1980_2020\n",
    "# bins_1980_2020 = [df_geographic_unique['yearOfLoss'].min(), 1990, 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "# labels_1980_2020 = [1980, 1990, 2000, 2010, 2020]\n",
    "\n",
    "# df_geographic_unique['yearOfLoss_1980_2020'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_1980_2020, labels=labels_1980_2020, right=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ced408b4-673a-4332-8bc1-fb789767a246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define bins and labels for yearOfLoss_1990_2021\n",
    "\n",
    "bins_1990_2021 = [df_geographic_unique['yearOfLoss'].min(), 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "labels_1990_2021 = [1990, 2000, 2010, 2020]\n",
    "\n",
    "df_geographic_unique['yearOfLoss_1990_2021'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_1990_2021, labels=labels_1990_2021, right=False).astype(int)\n",
    "\n",
    "bins_2000_2021 = [df_geographic_unique['yearOfLoss'].min(), 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "labels_2000_2021 = [1990, 2000, 2010, 2020]\n",
    "\n",
    "df_geographic_unique['yearOfLoss_2000_2021'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_2000_2021, labels=labels_2000_2021, right=False).astype(int)\n",
    "\n",
    "\n",
    "df_geographic_unique = df_geographic_unique.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b701bdf5-edf0-4758-985f-f0796e9d50bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2012, 2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25c9cac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the bins.\n",
    "# Adjusting the bins so that 2011 falls into the 2012 bin\n",
    "custom_bins = [0, 2000, 2010, 2012] + list(range(2013, 2023)) + [2024]\n",
    "\n",
    "# Step 2: Define the labels.\n",
    "# Adjusting the labels to reflect the new bin structure\n",
    "custom_labels = [0, 2000, 2010] + list(range(2012, 2023))  # The label 2022 will apply to both 2022 and 2023.\n",
    "\n",
    "# Ensure the number of labels is one less than the number of bin edges.\n",
    "assert len(custom_bins) == len(custom_labels) + 1, \"Number of bin labels must be one fewer than the number of bin edges.\"\n",
    "\n",
    "# Step 3: Apply the custom binning and create the 'zip_year_bin' column.\n",
    "df_geographic_unique['zip_year_bin'] = pd.cut(\n",
    "    df_geographic_unique['yearOfLoss'],\n",
    "    bins=custom_bins,\n",
    "    labels=custom_labels,\n",
    "    right=False,  # Ensuring the rightmost edge is exclusive.\n",
    "    include_lowest=True,  # Including the leftmost edge.\n",
    ").astype(int)  # Converting the resulting categories to integers for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783b44a-b8be-476a-9d41-89d5172f3f56",
   "metadata": {},
   "source": [
    "## Read shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dc2e6cf-9e37-4974-825f-24398be296b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default year of 2021\n"
     ]
    }
   ],
   "source": [
    "states = pygris.states()\n",
    "\n",
    "state_df = states[['STUSPS', 'NAME', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cced178-934a-411f-be8f-bf65fc418e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if all states found in our dataset are in the US Census Bureau TIGER/Line and cartographic boundary shapefiles\n",
    "\n",
    "unique_states = df_geographic_unique['state'].unique()\n",
    "state_STUSPS_unique = state_df['STUSPS'].unique()\n",
    "\n",
    "np.all(np.isin(unique_states, state_STUSPS_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce3582a8-cb16-48e5-9742-5fba90c5a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the parquet file\n",
    "df_read = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/lat_long_geometry.parquet.gzip\")\n",
    "\n",
    "# Convert the WKT strings back to geometries\n",
    "lat_long_df = gpd.GeoDataFrame(df_read, geometry=df_read['geometry'].apply(lambda x: shapely.wkt.loads(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "672d4d27-e73b-45bd-9638-296e91da2ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Blockgroup shapefile\n",
    "\n",
    "chunk_size = 40000 \n",
    "chunks = [x for x in range(0, 120000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/BG_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "BG_df= pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f7688-096e-4f05-a325-37ab0c476fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 50000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 300000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/zipcode_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "    \n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "zipcode_df = pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba7080-fa52-4e5b-b61c-4f7817bd031c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the parquet file\n",
    "df_read = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/County_geometry.parquet.gzip\")\n",
    "\n",
    "# Convert the WKT strings back to geometries\n",
    "County_df = gpd.GeoDataFrame(df_read, geometry=df_read['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179eb72-60d4-46b2-a158-dd020d882ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read shapefile of census tract code\n",
    "chunk_size = 30000 \n",
    "chunks = [x for x in range(0, 60000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/Tract_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "Tract_df= pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e939c53-2c45-4c6b-b263-2b73f8eaf43e",
   "metadata": {},
   "source": [
    "## Geometry Intersection creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7ff21-cf1d-4725-8e60-6f604c6f0a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_df.rename(columns={'geometry': 'geometry_state'}, inplace=True)\n",
    "lat_long_df.rename(columns={'geometry': 'geometry_lat_long'}, inplace=True)\n",
    "BG_df.rename(columns={'geometry': 'geometry_BG'}, inplace=True)\n",
    "zipcode_df.rename(columns={'geometry': 'geometry_zipcode'}, inplace=True)\n",
    "County_df.rename(columns={'geometry': 'geometry_county'}, inplace=True)\n",
    "Tract_df.rename(columns={'geometry': 'geometry_tract'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101cac4-cc10-407c-9c5b-14119f8f6ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter for post 2000\n",
    "# df_geographic_unique = df_geographic_unique[(df_geographic_unique['yearOfLoss_1980_2020']!=1980) & (df_geographic_unique['yearOfLoss_1980_2020']!=1980)]\n",
    "\n",
    "df_geographic_unique = df_geographic_unique[df_geographic_unique['yearOfLoss_2000_2021']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b1b6b-205a-4c13-9385-c089dcfb2136",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the multi-index on lat_long_df\n",
    "lat_long_df.set_index(['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "# Mapping the values\n",
    "df_geographic_unique['geometry_lat_long'] = df_geographic_unique.set_index(['latitude', 'longitude']).index.map(lat_long_df['geometry_lat_long'])\n",
    "\n",
    "# Resetting the index of lat_long_df (optional, but good practice)\n",
    "lat_long_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462231ec-209d-468c-bdd6-49e5fd648d92",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "BG_df.set_index(['GEOID'], inplace=True)\n",
    "df_geographic_unique['geometry_BG'] = df_geographic_unique.set_index(['censusBlockGroupFips']).index.map(BG_df['geometry_BG'])\n",
    "\n",
    "BG_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953d555-0408-41e3-8859-c04d1f9bacfc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "zipcode_df.set_index(['ZIPcode', 'year'], inplace=True)\n",
    "df_geographic_unique['geometry_zipcode'] = df_geographic_unique.set_index(['reportedZipCode', 'zip_year_bin']).index.map(zipcode_df['geometry_zipcode'])\n",
    "\n",
    "zipcode_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be627ecc-f569-41e8-961d-bf53859f69c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the multi-index on lat_long_df\n",
    "state_df.set_index(['STUSPS'], inplace=True)\n",
    "\n",
    "# Mapping the values\n",
    "df_geographic_unique['geometry_state'] = df_geographic_unique.set_index(['state']).index.map(state_df['geometry_state'])\n",
    "\n",
    "# Resetting the index of lat_long_df (optional, but good practice)\n",
    "state_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afc65a-c58f-4a20-8c94-ae0a572e2436",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "County_df.set_index(['CountyID'], inplace=True)\n",
    "df_geographic_unique['geometry_county'] = df_geographic_unique.set_index(['countyCode']).index.map(County_df['geometry_county'])\n",
    "\n",
    "# Resetting the index of County_df (return to multi-index)\n",
    "County_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db5e3b-9af9-4668-a2bc-fa037da2e7d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "Tract_df.set_index(['censusTractID'], inplace=True)\n",
    "df_geographic_unique['geometry_tract'] = df_geographic_unique.set_index(['censusTract']).index.map(Tract_df['geometry_tract'])\n",
    "\n",
    "# Resetting the index of County_df (return to multi-index)\n",
    "Tract_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dea85-62ce-400f-95f6-2379579f336d",
   "metadata": {},
   "source": [
    "## Drop rows with missing shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81019b69-3b25-47e4-960d-5b4fee6ad0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df_geographic_unique[(df_geographic_unique['geometry_BG'].notna())\n",
    "                              & (df_geographic_unique['geometry_county'].notna())\n",
    "                              & (df_geographic_unique['geometry_zipcode'].notna())\n",
    "                              & (df_geographic_unique['geometry_tract'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b9c2f-9ee8-4171-98c3-42fab1681427",
   "metadata": {},
   "source": [
    "## Creating the intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a5852-d041-4253-a1be-4b88fe46764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbb679-86d9-4962-b6fb-b2bec67effef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_geographic_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00facd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(df_geographic_unique['geometry_lat_long'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d460c-adb5-43bb-ad21-1181ff876ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_count = 0\n",
    "\n",
    "\n",
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df = gpd.GeoDataFrame(columns=['reportedZipCode', 'countyCode', 'censusTract',\n",
    "                                       'censusBlockGroupFips', 'latitude', 'longitude', 'year', 'year_zipcode', 'state', 'geometry_zipcode',\n",
    "                                       'geometry_county', 'geometry_tract','geometry_BG','geometry_lat_long','geometry_state',\n",
    "                                         'cbgInconsistent', 'tractInconsistent', 'countyInconsistent', 'stateInconsistent', 'latlongInconsistent', 'multiple', 'noOverlap', 'oneWrong'])\n",
    "\n",
    "# Iterate through each row in BG_df_1990 and each row in lat_long_df to find intersections\n",
    "for idx_unit, row_unit in df_geographic_unique.iterrows():\n",
    "    year = row_unit['yearOfLoss_1990_2021']\n",
    "    year_zipcode = row_unit['zip_year_bin']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    # Compute intersection geometry\n",
    "    #intersection_geometry = bg_geometry.intersection(lat_long_geometry).intersection(zipcode_geometry).intersection(county_geometry).intersection(state_geometry).intersection(tract_geometry)\n",
    "    \n",
    "    # First intersection\n",
    "    intersection_1 = bg_geometry.intersection(lat_long_geometry)\n",
    "\n",
    "    # Second intersection\n",
    "    intersection_2 = intersection_1.intersection(zipcode_geometry)\n",
    "\n",
    "    # Third intersection\n",
    "    \n",
    "    try:\n",
    "        intersection_3 = intersection_2.intersection(county_geometry)\n",
    "    except Exception as e:\n",
    "        if \"TopologyException\" in str(e):\n",
    "            error_count += 1\n",
    "            # Apply a small buffer (e.g., 0.0001) to the geometry and retry\n",
    "            buffered_geom = intersection_2.buffer(0.0001)\n",
    "            intersection_3 = buffered_geom.intersection(county_geometry)\n",
    "    \n",
    "    \n",
    "    # Fourth intersection\n",
    "    intersection_4 = intersection_3.intersection(state_geometry)\n",
    "\n",
    "    try:\n",
    "        intersection_geometry = intersection_4.intersection(tract_geometry)\n",
    "    except Exception as e:\n",
    "        if \"TopologyException\" in str(e):\n",
    "            error_count += 1\n",
    "            # Apply a small buffer (e.g., 0.0001) to the geometry and retry\n",
    "            buffered_geom = intersection_4.buffer(0.0001)\n",
    "            intersection_geometry = buffered_geom.intersection(tract_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df = pd.concat([new_unit_df, pd.DataFrame({\n",
    "            'reportedZipCode': [zipcode],\n",
    "            'countyCode': [county_id],\n",
    "            'censusTract': [tract_id],\n",
    "            'censusBlockGroupFips': [bg_id],\n",
    "            'latitude': [lat],\n",
    "            'longitude': [long],\n",
    "            'year': [year],\n",
    "            'year_zipcode': [year_zipcode],\n",
    "            'state': [state],\n",
    "            'geometry_zipcode': [zipcode_geometry],\n",
    "            'geometry_county': [county_geometry],\n",
    "            'geometry_tract': [tract_geometry],\n",
    "            'geometry_BG': [bg_geometry],\n",
    "            'geometry_lat_long': [lat_long_geometry],\n",
    "            'geometry_state': [state_geometry]\n",
    "        })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9518b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(new_unit_df))\n",
    "print(error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72508938-9d19-4321-aaa1-387c5a743c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    year_zipcode = row_unit['zip_year_bin']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = lat_long_geometry.intersection(zipcode_geometry).intersection(county_geometry).intersection(state_geometry).intersection(tract_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit, 'cbgInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit, 'cbgInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f4948e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['cbgInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf67d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    year_zipcode = row_unit['zip_year_bin']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(county_geometry).intersection(state_geometry).intersection(lat_long_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'tractInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'tractInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e027cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['tractInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e87c0-73df-4bf7-866a-d7c62547ca2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(tract_geometry).intersection(state_geometry).intersection(lat_long_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'countyInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'countyInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e7f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['countyInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae01b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(tract_geometry).intersection(county_geometry).intersection(lat_long_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'stateInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'stateInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30abd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['stateInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88107cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(tract_geometry).intersection(county_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'latlongInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'latlongInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd920c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['latlongInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff2566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = bg_geometry.intersection(lat_long_geometry).intersection(tract_geometry).intersection(county_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'zipInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'zipInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c1070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(new_unit_df['zipInconsistent'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fb104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (new_unit_df['latlongInconsistent'] +  new_unit_df['zipInconsistent']+ new_unit_df['stateInconsistent'] + new_unit_df['countyInconsistent'] + new_unit_df['tractInconsistent'] + new_unit_df['cbgInconsistent']) > 1\n",
    "new_unit_df.loc[mask, 'multiple'] = 1\n",
    "new_unit_df.loc[~mask, 'multiple'] = 0\n",
    "\n",
    "print(sum(new_unit_df['multiple']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb224d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153d7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] + \n",
    "             new_unit_df['tractInconsistent'] + \n",
    "             new_unit_df['cbgInconsistent'] +\n",
    "             new_unit_df['zipInconsistent']) == 0\n",
    "\n",
    "new_unit_df['noOverlap'] = 0  # Default to 0\n",
    "new_unit_df.loc[condition, 'noOverlap'] = 1\n",
    "\n",
    "print(sum(new_unit_df['noOverlap']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844e60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] + \n",
    "             new_unit_df['tractInconsistent'] + \n",
    "             new_unit_df['cbgInconsistent'] +\n",
    "             new_unit_df['zipInconsistent']) == 1\n",
    "\n",
    "new_unit_df['oneWrong'] = 0  # Default to 0\n",
    "new_unit_df.loc[condition, 'oneWrong'] = 1\n",
    "\n",
    "print(sum(new_unit_df['oneWrong']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280443c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the count dictionary for 'Wrong' values\n",
    "wrong_counts = {\n",
    "    'lat_long_geometry': 0,\n",
    "    'state_geometry': 0,\n",
    "    'county_geometry': 0,\n",
    "    'tract_geometry': 0,\n",
    "    'bg_geometry': 0,\n",
    "    'zip_geometry': 0  # added for zip codes\n",
    "}\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    if row_unit['oneWrong'] == 1:\n",
    "        if row_unit['latlongInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'lat_long_geometry'] = 'Wrong'\n",
    "            wrong_counts['lat_long_geometry'] += 1\n",
    "        if row_unit['stateInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'state_geometry'] = 'Wrong'\n",
    "            wrong_counts['state_geometry'] += 1\n",
    "        if row_unit['countyInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'county_geometry'] = 'Wrong'\n",
    "            wrong_counts['county_geometry'] += 1\n",
    "        if row_unit['tractInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'tract_geometry'] = 'Wrong'\n",
    "            wrong_counts['tract_geometry'] += 1\n",
    "        if row_unit['cbgInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'bg_geometry'] = 'Wrong'\n",
    "            wrong_counts['bg_geometry'] += 1\n",
    "        if row_unit['zipInconsistent'] == 1:  # added for zip codes\n",
    "            new_unit_df.at[idx_unit, 'zip_geometry'] = 'Wrong'\n",
    "            wrong_counts['zip_geometry'] += 1\n",
    "\n",
    "# Print the 'Wrong' counts\n",
    "for category, count in wrong_counts.items():\n",
    "    print(f\"{category}: {count} 'Wrong' values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c96507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['CBG_Zip_Mutually_Inconsistent'] = np.where(\n",
    "    (new_unit_df['latlongInconsistent'] == 0) & \n",
    "    (new_unit_df['cbgInconsistent'] == 1) & \n",
    "    (new_unit_df['zipInconsistent'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e764542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(new_unit_df['CBG_Zip_Mutually_Inconsistent'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840d639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(new_unit_df[(new_unit_df['latlongInconsistent'] == 1) &(new_unit_df['cbgInconsistent'] == 1) & ((new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] + \n",
    "             new_unit_df['tractInconsistent'] + \n",
    "             new_unit_df['cbgInconsistent'] +\n",
    "             new_unit_df['zipInconsistent'])  == 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d87104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(new_unit_df['latlongInconsistent'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a071b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb9fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'geometry_tract', 'geometry_BG', 'geometry_zipcode',\n",
    "    'geometry_county', 'geometry_state', 'geometry_lat_long'\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "new_unit_df = new_unit_df.drop(columns= columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d63f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'zipInconsistent' column to integer type.\n",
    "new_unit_df['zipInconsistent'] = new_unit_df['zipInconsistent'].astype(int)\n",
    "\n",
    "# Save to CSV without index.\n",
    "new_unit_df.to_parquet(r'C:\\Users\\Asus\\Box\\Flood Damage PredictionProject\\Dataset\\InconsistencyDataframes\\inconsistency_dataframe_1.parquet.gzip', compression = 'gzip',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f68b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(new_unit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701caf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = new_unit_df[new_unit_df.duplicated(keep=False)]\n",
    "\n",
    "print(duplicates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
