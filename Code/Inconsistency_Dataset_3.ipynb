{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a33fa-936f-4abe-98dd-197343e523df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "#Packages\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import pygris\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276995e-b191-495a-a279-935ed0fe65b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/FimaNfipClaims.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594186ed-291b-4962-a2de-f86b586a617a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Third Dataset [NA County, post 2000]\n",
    "## No geographic values missing, no shapefiles missing, post 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259aa2a8-afb3-47d8-bcfd-32b053e0e958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df[['state', 'reportedZipCode', 'countyCode', 'censusTract', 'censusBlockGroupFips', 'latitude', 'longitude', 'yearOfLoss']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f82936-6fe6-467d-b27e-d0b5e43104ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining conditions\n",
    "condition1 = (df_geographic_unique['latitude'].notna() & \n",
    "              df_geographic_unique['censusBlockGroupFips'].notna() & \n",
    "              df_geographic_unique['countyCode'].isna() & \n",
    "              df_geographic_unique['reportedZipCode'].notna())\n",
    "\n",
    "# Filtering the dataframe based on the combined conditions\n",
    "df_geographic_unique = df_geographic_unique[condition1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7262b4c-9f66-487c-9ac1-8eb07cb35388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fefcacd-91e5-4c57-90ae-a5b478ae7a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sum(df_geographic_unique['state'].isna()))\n",
    "print(sum(df_geographic_unique['reportedZipCode'].isna()))\n",
    "print(sum(df_geographic_unique['countyCode'].isna()))\n",
    "print(sum(df_geographic_unique['censusTract'].isna()))\n",
    "print(sum(df_geographic_unique['censusBlockGroupFips'].isna()))\n",
    "print(sum(df_geographic_unique['latitude'].isna()))\n",
    "print(sum(df_geographic_unique['yearOfLoss'].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bcc5a-7601-45f0-a129-d3511ab53afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique['reportedZipCode'] = df_geographic_unique['reportedZipCode'].dropna().astype(int).astype(str)\n",
    "df_geographic_unique['reportedZipCode'] = [zipcode.zfill(5) for zipcode in df_geographic_unique['reportedZipCode']]\n",
    "\n",
    "df_geographic_unique['censusBlockGroupFips'] = [str(int(float(i))) for i in df_geographic_unique['censusBlockGroupFips']]\n",
    "df_geographic_unique['censusBlockGroupFips'] = [censusBG.zfill(12) for censusBG in df_geographic_unique['censusBlockGroupFips']]\n",
    "\n",
    "df_geographic_unique['censusTract'] = [str(int(float(i))) for i in df_geographic_unique['censusTract']]\n",
    "df_geographic_unique['censusTract'] = [censusBG.zfill(11) for censusBG in df_geographic_unique['censusTract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59938e49-19f4-4a5d-9c40-539c166d91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define bins and labels for yearOfLoss_1980_2020\n",
    "# bins_1980_2020 = [df_geographic_unique['yearOfLoss'].min(), 1990, 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "# labels_1980_2020 = [1980, 1990, 2000, 2010, 2020]\n",
    "\n",
    "# df_geographic_unique['yearOfLoss_1980_2020'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_1980_2020, labels=labels_1980_2020, right=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced408b4-673a-4332-8bc1-fb789767a246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define bins and labels for yearOfLoss_2000_2021\n",
    "bins_2000_2021 = [df_geographic_unique['yearOfLoss'].min(), 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "labels_2000_2021 = [0, 2000, 2010, 2020]\n",
    "\n",
    "df_geographic_unique['yearOfLoss_2000_2021'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_2000_2021, labels=labels_2000_2021, right=False).astype(int)\n",
    "\n",
    "# Define bins and labels for yearOfLoss_1990_2021\n",
    "bins_1990_2021 = [df_geographic_unique['yearOfLoss'].min(), 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "labels_1990_2021 = [1990, 2000, 2010, 2020]\n",
    "\n",
    "df_geographic_unique['yearOfLoss_1990_2021'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_1990_2021, labels=labels_1990_2021, right=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3342268-f6c3-41a0-b21a-4f6f4efd66db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783b44a-b8be-476a-9d41-89d5172f3f56",
   "metadata": {},
   "source": [
    "## Read shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2e6cf-9e37-4974-825f-24398be296b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = pygris.states()\n",
    "\n",
    "state_df = states[['STUSPS', 'NAME', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cced178-934a-411f-be8f-bf65fc418e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking if all states found in our dataset are in the US Census Bureau TIGER/Line and cartographic boundary shapefiles\n",
    "\n",
    "unique_states = df_geographic_unique['state'].unique()\n",
    "state_STUSPS_unique = state_df['STUSPS'].unique()\n",
    "\n",
    "np.all(np.isin(unique_states, state_STUSPS_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3582a8-cb16-48e5-9742-5fba90c5a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the parquet file\n",
    "df_read = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/lat_long_geometry.parquet.gzip\")\n",
    "\n",
    "# Convert the WKT strings back to geometries\n",
    "lat_long_df = gpd.GeoDataFrame(df_read, geometry=df_read['geometry'].apply(lambda x: shapely.wkt.loads(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d4d27-e73b-45bd-9638-296e91da2ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 40000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 320000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/BG_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "BG_df = pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f7688-096e-4f05-a325-37ab0c476fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 25000  # adjust based on your system's capabilities\n",
    "chunks = [x for x in range(0, 100000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/zipcode_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "    \n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "zipcode_df = pd.concat(gdf_list, ignore_index=True)\n",
    "\n",
    "zipcode_df['year'] = zipcode_df['year'].replace({2012: 2010, 2021: 2020})\n",
    "zipcode_df = zipcode_df.drop_duplicates(subset=['ZIPcode', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179eb72-60d4-46b2-a158-dd020d882ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the parquet file for Tract_shapefile\n",
    "chunk_size = 30000 \n",
    "chunks = [x for x in range(0, 180000, chunk_size)]\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for start in chunks:\n",
    "    end = start + chunk_size\n",
    "    temp_df = pd.read_parquet(f\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/Tract_geometry_{start}_{end}.parquet.gzip\")\n",
    "    gdf_read = gpd.GeoDataFrame(temp_df, geometry=temp_df['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "    gdf_list.append(gdf_read)\n",
    "\n",
    "# Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "Tract_df= pd.concat(gdf_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e939c53-2c45-4c6b-b263-2b73f8eaf43e",
   "metadata": {},
   "source": [
    "## Geometry Intersection creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7ff21-cf1d-4725-8e60-6f604c6f0a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_df.rename(columns={'geometry': 'geometry_state'}, inplace=True)\n",
    "lat_long_df.rename(columns={'geometry': 'geometry_lat_long'}, inplace=True)\n",
    "BG_df.rename(columns={'geometry': 'geometry_BG'}, inplace=True)\n",
    "zipcode_df.rename(columns={'geometry': 'geometry_zipcode'}, inplace=True)\n",
    "Tract_df.rename(columns={'GEOID':'censusTractID','geometry': 'geometry_tract'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101cac4-cc10-407c-9c5b-14119f8f6ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter for post 2000\n",
    "# df_geographic_unique = df_geographic_unique[(df_geographic_unique['yearOfLoss_1980_2020']!=1980) & (df_geographic_unique['yearOfLoss_1980_2020']!=1980)]\n",
    "\n",
    "df_geographic_unique = df_geographic_unique[df_geographic_unique['yearOfLoss_2000_2021']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b1b6b-205a-4c13-9385-c089dcfb2136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the multi-index on lat_long_df\n",
    "lat_long_df.set_index(['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "# Mapping the values\n",
    "df_geographic_unique['geometry_lat_long'] = df_geographic_unique.set_index(['latitude', 'longitude']).index.map(lat_long_df['geometry_lat_long'])\n",
    "\n",
    "# Resetting the index of lat_long_df (optional, but good practice)\n",
    "lat_long_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462231ec-209d-468c-bdd6-49e5fd648d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "BG_df.set_index(['GEOID', 'year'], inplace=True)\n",
    "df_geographic_unique['geometry_BG'] = df_geographic_unique.set_index(['censusBlockGroupFips', 'yearOfLoss_1990_2021']).index.map(BG_df['geometry_BG'])\n",
    "\n",
    "# Resetting the index of BG_df (return to multi-index)\n",
    "BG_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953d555-0408-41e3-8859-c04d1f9bacfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "zipcode_df.set_index(['ZIPcode', 'year'], inplace=True)\n",
    "df_geographic_unique['geometry_zipcode'] = df_geographic_unique.set_index(['reportedZipCode', 'yearOfLoss_2000_2021']).index.map(zipcode_df['geometry_zipcode'])\n",
    "\n",
    "# Resetting the index of zipcode_df (return to multi-index)\n",
    "zipcode_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be627ecc-f569-41e8-961d-bf53859f69c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the multi-index on lat_long_df\n",
    "state_df.set_index(['STUSPS'], inplace=True)\n",
    "\n",
    "# Mapping the values\n",
    "df_geographic_unique['geometry_state'] = df_geographic_unique.set_index(['state']).index.map(state_df['geometry_state'])\n",
    "\n",
    "# Resetting the index of lat_long_df (optional, but good practice)\n",
    "state_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db5e3b-9af9-4668-a2bc-fa037da2e7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "Tract_df.set_index(['censusTractID', 'year'], inplace=True)\n",
    "df_geographic_unique['geometry_tract'] = df_geographic_unique.set_index(['censusTract', 'yearOfLoss_2000_2021']).index.map(Tract_df['geometry_tract'])\n",
    "\n",
    "# Resetting the index of Tract_df (return to multi-index)\n",
    "Tract_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dea85-62ce-400f-95f6-2379579f336d",
   "metadata": {},
   "source": [
    "## Drop rows with missing shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81019b69-3b25-47e4-960d-5b4fee6ad0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df_geographic_unique[(df_geographic_unique['geometry_BG'].notna())\n",
    "                              & (df_geographic_unique['geometry_zipcode'].notna())\n",
    "                              & (df_geographic_unique['geometry_tract'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b9c2f-9ee8-4171-98c3-42fab1681427",
   "metadata": {},
   "source": [
    "## Creating the intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a5852-d041-4253-a1be-4b88fe46764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4686bd6-122f-452f-b086-6e3656b187f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_geographic_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d460c-adb5-43bb-ad21-1181ff876ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df = gpd.GeoDataFrame(columns=['reportedZipCode', 'countyCode', 'censusTract',\n",
    "                                       'censusBlockGroupFips', 'latitude', 'longitude', 'year', 'state', 'geometry_zipcode',\n",
    "                                        'geometry_tract','geometry_BG','geometry_lat_long','geometry_state',\n",
    "                                         'cbgInconsistent', 'tractInconsistent', 'countyInconsistent', 'stateInconsistent', 'latlongInconsistent', 'multiple', 'noOverlap', 'oneWrong'])\n",
    "\n",
    "# Iterate through each row in BG_df_1990 and each row in lat_long_df to find intersections\n",
    "for idx_unit, row_unit in df_geographic_unique.iterrows():\n",
    "    year = row_unit['yearOfLoss_1990_2021']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    # Compute intersection geometry\n",
    "    intersection_geometry = bg_geometry.intersection(lat_long_geometry).intersection(tract_geometry).intersection(zipcode_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df = pd.concat([new_unit_df, pd.DataFrame({\n",
    "            'reportedZipCode': [zipcode],\n",
    "            'countyCode': [county_id],\n",
    "            'censusTract': [tract_id],\n",
    "            'censusBlockGroupFips': [bg_id],\n",
    "            'latitude': [lat],\n",
    "            'longitude': [long],\n",
    "            'year': [year],\n",
    "            'state': [state],\n",
    "            'geometry_zipcode': [zipcode_geometry],\n",
    "            'geometry_tract': [tract_geometry],\n",
    "            'geometry_BG': [bg_geometry],\n",
    "            'geometry_lat_long': [lat_long_geometry],\n",
    "            'geometry_state': [state_geometry]\n",
    "        })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9518b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(new_unit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72508938-9d19-4321-aaa1-387c5a743c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "\n",
    "    intersection_geometry = lat_long_geometry.intersection(tract_geometry).intersection(zipcode_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit, 'cbgInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit, 'cbgInconsistent'] = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f4948e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['cbgInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf67d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(lat_long_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'tractInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'tractInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e027cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['tractInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e87c0-73df-4bf7-866a-d7c62547ca2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    intersection_geometry = bg_geometry.intersection(lat_long_geometry).intersection(zipcode_geometry).intersection(tract_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'countyInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'countyInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e7f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['countyInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae01b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "\n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(tract_geometry).intersection(lat_long_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'stateInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'stateInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30abd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['stateInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88107cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    intersection_geometry = bg_geometry.intersection(zipcode_geometry).intersection(tract_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'latlongInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'latlongInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd920c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['latlongInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff2566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    bg_geometry = row_unit['geometry_BG']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    tract_geometry = row_unit['geometry_tract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode_geometry = row_unit['geometry_zipcode']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    intersection_geometry = bg_geometry.intersection(lat_long_geometry).intersection(tract_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'zipInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'zipInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c1070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(new_unit_df['zipInconsistent'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fb104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (new_unit_df['latlongInconsistent'] +  new_unit_df['zipInconsistent']+ new_unit_df['stateInconsistent'] + new_unit_df['countyInconsistent'] + new_unit_df['tractInconsistent'] + new_unit_df['cbgInconsistent']) > 1\n",
    "new_unit_df.loc[mask, 'multiple'] = 1\n",
    "new_unit_df.loc[~mask, 'multiple'] = 0\n",
    "\n",
    "print(sum(new_unit_df['multiple']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb224d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153d7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] + \n",
    "             new_unit_df['tractInconsistent'] + \n",
    "             new_unit_df['cbgInconsistent'] +\n",
    "             new_unit_df['zipInconsistent']) == 0\n",
    "\n",
    "new_unit_df['noOverlap'] = 0  # Default to 0\n",
    "new_unit_df.loc[condition, 'noOverlap'] = 1\n",
    "\n",
    "print(sum(new_unit_df['noOverlap']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844e60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] + \n",
    "             new_unit_df['tractInconsistent'] + \n",
    "             new_unit_df['cbgInconsistent'] +\n",
    "             new_unit_df['zipInconsistent']) == 1\n",
    "\n",
    "new_unit_df['oneWrong'] = 0  # Default to 0\n",
    "new_unit_df.loc[condition, 'oneWrong'] = 1\n",
    "\n",
    "print(sum(new_unit_df['oneWrong']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280443c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the count dictionary for 'Wrong' values\n",
    "wrong_counts = {\n",
    "    'lat_long_geometry': 0,\n",
    "    'state_geometry': 0,\n",
    "    'county_geometry': 0,\n",
    "    'tract_geometry': 0,\n",
    "    'bg_geometry': 0,\n",
    "    'zip_geometry': 0  # added for zip codes\n",
    "}\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    if row_unit['oneWrong'] == 1:\n",
    "        if row_unit['latlongInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'lat_long_geometry'] = 'Wrong'\n",
    "            wrong_counts['lat_long_geometry'] += 1\n",
    "        if row_unit['stateInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'state_geometry'] = 'Wrong'\n",
    "            wrong_counts['state_geometry'] += 1\n",
    "        if row_unit['tractInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'tract_geometry'] = 'Wrong'\n",
    "            wrong_counts['tract_geometry'] += 1\n",
    "        if row_unit['cbgInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'bg_geometry'] = 'Wrong'\n",
    "            wrong_counts['bg_geometry'] += 1\n",
    "        if row_unit['zipInconsistent'] == 1:  # added for zip codes\n",
    "            new_unit_df.at[idx_unit, 'zip_geometry'] = 'Wrong'\n",
    "            wrong_counts['zip_geometry'] += 1\n",
    "\n",
    "# Print the 'Wrong' counts\n",
    "for category, count in wrong_counts.items():\n",
    "    print(f\"{category}: {count} 'Wrong' values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840d639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(new_unit_df[(new_unit_df['latlongInconsistent'] == 1) &(new_unit_df['cbgInconsistent'] == 1) & ((new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] + \n",
    "             new_unit_df['tractInconsistent'] + \n",
    "             new_unit_df['cbgInconsistent'] +\n",
    "             new_unit_df['zipInconsistent'])  == 2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
