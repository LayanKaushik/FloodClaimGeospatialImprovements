{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a33fa-936f-4abe-98dd-197343e523df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "#Packages\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import pygris\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276995e-b191-495a-a279-935ed0fe65b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/FimaNfipClaims.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31689785-1dc6-411d-8582-bd2d2ae8bdb8",
   "metadata": {},
   "source": [
    "## First Dataset [censusBlockGroupFips and Tract NA (Missing together) and NA Zipcode]\n",
    "## No geographic values missing, no shapefiles missing, post 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259aa2a8-afb3-47d8-bcfd-32b053e0e958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df[['state', 'reportedZipCode', 'countyCode', 'censusTract', 'censusBlockGroupFips', 'latitude', 'longitude', 'yearOfLoss']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f82936-6fe6-467d-b27e-d0b5e43104ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining conditions\n",
    "condition1 = (df_geographic_unique['latitude'].notna() & \n",
    "              df_geographic_unique['censusBlockGroupFips'].isna() & \n",
    "              df_geographic_unique['countyCode'].notna() & \n",
    "              df_geographic_unique['reportedZipCode'].isna())\n",
    "\n",
    "condition2 = (df_geographic_unique['latitude'].notna() & \n",
    "              df_geographic_unique['censusBlockGroupFips'].isna() & \n",
    "              df_geographic_unique['countyCode'].notna() & \n",
    "              df_geographic_unique['reportedZipCode'].notna() &\n",
    "              (df_geographic_unique['yearOfLoss'] < 2000))\n",
    "\n",
    "# Filtering the dataframe based on the combined conditions\n",
    "df_geographic_unique = df_geographic_unique[condition1 | condition2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7262b4c-9f66-487c-9ac1-8eb07cb35388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fefcacd-91e5-4c57-90ae-a5b478ae7a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sum(df_geographic_unique['state'].isna()))\n",
    "print(sum(df_geographic_unique['reportedZipCode'].isna()))\n",
    "print(sum(df_geographic_unique['countyCode'].isna()))\n",
    "print(sum(df_geographic_unique['censusTract'].isna()))\n",
    "print(sum(df_geographic_unique['censusBlockGroupFips'].isna()))\n",
    "print(sum(df_geographic_unique['latitude'].isna()))\n",
    "print(sum(df_geographic_unique['yearOfLoss'].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bcc5a-7601-45f0-a129-d3511ab53afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique['countyCode'] = [str(int(float(i))) for i in df_geographic_unique['countyCode']]\n",
    "df_geographic_unique['countyCode'] = [censusBG.zfill(5) for censusBG in df_geographic_unique['countyCode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349c759-5ca1-458d-9915-d1dd177f800d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define bins and labels for yearOfLoss_1980_2020\n",
    "# bins_1980_2020 = [df_geographic_unique['yearOfLoss'].min(), 1990, 2000, 2010, 2020, df_geographic_unique['yearOfLoss'].max() + 1]\n",
    "# labels_1980_2020 = [1980, 1990, 2000, 2010, 2020]\n",
    "\n",
    "# df_geographic_unique['yearOfLoss_1980_2020'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_1980_2020, labels=labels_1980_2020, right=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced408b4-673a-4332-8bc1-fb789767a246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define bins and labels for yearOfLoss_2000_2021\n",
    "bins_2000_2021 = [0, 2000, 2010, 2020, 2030]\n",
    "labels_2000_2021 = [1990, 2000, 2010, 2020]\n",
    "\n",
    "df_geographic_unique['yearOfLoss_2000_2021'] = pd.cut(df_geographic_unique['yearOfLoss'], bins=bins_2000_2021, labels=labels_2000_2021, right=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3342268-f6c3-41a0-b21a-4f6f4efd66db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783b44a-b8be-476a-9d41-89d5172f3f56",
   "metadata": {},
   "source": [
    "## Read shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2e6cf-9e37-4974-825f-24398be296b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = pygris.states()\n",
    "\n",
    "state_df = states[['STUSPS', 'NAME', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cced178-934a-411f-be8f-bf65fc418e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking if all states found in our dataset are in the US Census Bureau TIGER/Line and cartographic boundary shapefiles\n",
    "\n",
    "unique_states = df_geographic_unique['state'].unique()\n",
    "state_STUSPS_unique = state_df['STUSPS'].unique()\n",
    "\n",
    "np.all(np.isin(unique_states, state_STUSPS_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3582a8-cb16-48e5-9742-5fba90c5a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the parquet file\n",
    "df_read = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/lat_long_geometry.parquet.gzip\")\n",
    "\n",
    "# Convert the WKT strings back to geometries\n",
    "lat_long_df = gpd.GeoDataFrame(df_read, geometry=df_read['geometry'].apply(lambda x: shapely.wkt.loads(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba7080-fa52-4e5b-b61c-4f7817bd031c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the parquet file\n",
    "df_read = pd.read_parquet(\"C:/Users/Asus/Box/Flood Damage PredictionProject/Dataset/County_geometry.parquet.gzip\")\n",
    "\n",
    "# Convert the WKT strings back to geometries\n",
    "County_df = gpd.GeoDataFrame(df_read, geometry=df_read['geometry'].apply(lambda x: shapely.wkt.loads(x)))\n",
    "\n",
    "County_df['year'] = County_df['year'].replace({2012: 2010, 2021: 2020})\n",
    "County_df = County_df.drop_duplicates(subset=['CountyID', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e939c53-2c45-4c6b-b263-2b73f8eaf43e",
   "metadata": {},
   "source": [
    "## Geometry Intersection creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7ff21-cf1d-4725-8e60-6f604c6f0a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_df.rename(columns={'geometry': 'geometry_state'}, inplace=True)\n",
    "lat_long_df.rename(columns={'geometry': 'geometry_lat_long'}, inplace=True)\n",
    "County_df.rename(columns={'geometry': 'geometry_county'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973fd9f-d9f0-474f-b85c-2f7ad472b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "County_df = County_df[County_df['year'] == 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101cac4-cc10-407c-9c5b-14119f8f6ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter for post 2000\n",
    "# df_geographic_unique = df_geographic_unique[(df_geographic_unique['yearOfLoss_1980_2020']!=1980) & (df_geographic_unique['yearOfLoss_1980_2020']!=1980)]\n",
    "\n",
    "df_geographic_unique = df_geographic_unique[df_geographic_unique['yearOfLoss_2000_2021']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b1b6b-205a-4c13-9385-c089dcfb2136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the multi-index on lat_long_df\n",
    "lat_long_df.set_index(['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "# Mapping the values\n",
    "df_geographic_unique['geometry_lat_long'] = df_geographic_unique.set_index(['latitude', 'longitude']).index.map(lat_long_df['geometry_lat_long'])\n",
    "\n",
    "# Resetting the index of lat_long_df (optional, but good practice)\n",
    "lat_long_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be627ecc-f569-41e8-961d-bf53859f69c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the multi-index on lat_long_df\n",
    "state_df.set_index(['STUSPS'], inplace=True)\n",
    "\n",
    "# Mapping the values\n",
    "df_geographic_unique['geometry_state'] = df_geographic_unique.set_index(['state']).index.map(state_df['geometry_state'])\n",
    "\n",
    "# Resetting the index of lat_long_df (optional, but good practice)\n",
    "state_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afc65a-c58f-4a20-8c94-ae0a572e2436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial mapping with multi-index\n",
    "County_df.set_index(['CountyID'], inplace=True)\n",
    "df_geographic_unique['geometry_county'] = df_geographic_unique.set_index(['countyCode']).index.map(County_df['geometry_county'])\n",
    "\n",
    "# Resetting the index of County_df (return to multi-index)\n",
    "County_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dea85-62ce-400f-95f6-2379579f336d",
   "metadata": {},
   "source": [
    "## Drop rows with missing shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81019b69-3b25-47e4-960d-5b4fee6ad0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_geographic_unique = df_geographic_unique[(df_geographic_unique['geometry_county'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b9c2f-9ee8-4171-98c3-42fab1681427",
   "metadata": {},
   "source": [
    "## Creating the intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a5852-d041-4253-a1be-4b88fe46764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5624bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_geographic_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d460c-adb5-43bb-ad21-1181ff876ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty GeoDataFrame to store the intersection results\n",
    "new_unit_df = gpd.GeoDataFrame(columns=['reportedZipCode', 'countyCode', 'censusTract',\n",
    "                                       'censusBlockGroupFips', 'latitude', 'longitude', 'yearOfLoss_2000_2021', 'state',\n",
    "                                       'geometry_county','geometry_lat_long','geometry_state',\n",
    "                                         'cbgInconsistent', 'tractInconsistent', 'countyInconsistent', \n",
    "                                        'stateInconsistent', 'latlongInconsistent', 'multiple', 'noOverlap', 'oneWrong'])\n",
    "\n",
    "# Iterate through each row in BG_df_1990 and each row in lat_long_df to find intersections\n",
    "for idx_unit, row_unit in df_geographic_unique.iterrows():\n",
    "    year = row_unit['yearOfLoss_2000_2021']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "    \n",
    "    # Compute intersection geometry\n",
    "    intersection_geometry = lat_long_geometry.intersection(county_geometry).intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df = pd.concat([new_unit_df, pd.DataFrame({\n",
    "            'reportedZipCode': [zipcode],\n",
    "            'countyCode': [county_id],\n",
    "            'censusTract': [tract_id],\n",
    "            'censusBlockGroupFips': [bg_id],\n",
    "            'latitude': [lat],\n",
    "            'longitude': [long],\n",
    "            'year': [year],\n",
    "            'state': [state],\n",
    "            'geometry_county': [county_geometry],\n",
    "            'geometry_lat_long': [lat_long_geometry],\n",
    "            'geometry_state': [state_geometry]\n",
    "        })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa79e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(new_unit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e87c0-73df-4bf7-866a-d7c62547ca2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "\n",
    "    intersection_geometry = state_geometry.intersection(lat_long_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'countyInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'countyInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610219d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['countyInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae01b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode = row_unit['reportedZipCode']   \n",
    "\n",
    "    intersection_geometry = county_geometry.intersection(lat_long_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'stateInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'stateInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2401afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['stateInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88107cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    year = row_unit['year']\n",
    "    bg_id = row_unit['censusBlockGroupFips']\n",
    "    tract_id = row_unit['censusTract']\n",
    "    county_id = row_unit['countyCode']\n",
    "    county_geometry = row_unit['geometry_county']\n",
    "    state = row_unit['state']\n",
    "    state_geometry = row_unit['geometry_state']\n",
    "    lat_long_geometry = row_unit['geometry_lat_long']\n",
    "    lat = row_unit['latitude']\n",
    "    long = row_unit['longitude']\n",
    "    zipcode = row_unit['reportedZipCode']\n",
    "\n",
    "    intersection_geometry = county_geometry.intersection(state_geometry)\n",
    "\n",
    "    if intersection_geometry is None or intersection_geometry.is_empty:\n",
    "        new_unit_df.at[idx_unit,'latlongInconsistent'] = 0\n",
    "    else:\n",
    "        new_unit_df.at[idx_unit,'latlongInconsistent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6c544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df['latlongInconsistent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fb104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (new_unit_df['latlongInconsistent'] +   new_unit_df['stateInconsistent'] + new_unit_df['countyInconsistent'] ) > 1\n",
    "new_unit_df.loc[mask, 'multiple'] = 1\n",
    "new_unit_df.loc[~mask, 'multiple'] = 0\n",
    "\n",
    "print(sum(new_unit_df['multiple']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38105b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153d7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent']   ) == 0\n",
    "\n",
    "new_unit_df['noOverlap'] = 0  # Default to 0\n",
    "new_unit_df.loc[condition, 'noOverlap'] = 1\n",
    "\n",
    "print(sum(new_unit_df['noOverlap']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603737b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (new_unit_df['latlongInconsistent'] + \n",
    "             new_unit_df['stateInconsistent'] + \n",
    "             new_unit_df['countyInconsistent'] )  == 1\n",
    "\n",
    "new_unit_df['oneWrong'] = 0  # Default to 0\n",
    "new_unit_df.loc[condition, 'oneWrong'] = 1\n",
    "\n",
    "print(sum(new_unit_df['oneWrong']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280443c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the count dictionary for 'Wrong' values\n",
    "wrong_counts = {\n",
    "    'lat_long_geometry': 0,\n",
    "    'state_geometry': 0,\n",
    "    'county_geometry': 0,\n",
    "    'tract_geometry': 0,\n",
    "    'bg_geometry': 0,\n",
    "    'zip_geometry': 0  # added for zip codes\n",
    "}\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for idx_unit, row_unit in new_unit_df.iterrows():\n",
    "    if row_unit['oneWrong'] == 1:\n",
    "        if row_unit['latlongInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'lat_long_geometry'] = 'Wrong'\n",
    "            wrong_counts['lat_long_geometry'] += 1\n",
    "        if row_unit['stateInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'state_geometry'] = 'Wrong'\n",
    "            wrong_counts['state_geometry'] += 1\n",
    "        if row_unit['countyInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'county_geometry'] = 'Wrong'\n",
    "            wrong_counts['county_geometry'] += 1\n",
    "        if row_unit['tractInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'tract_geometry'] = 'Wrong'\n",
    "            wrong_counts['tract_geometry'] += 1\n",
    "        if row_unit['cbgInconsistent'] == 1:\n",
    "            new_unit_df.at[idx_unit, 'bg_geometry'] = 'Wrong'\n",
    "            wrong_counts['bg_geometry'] += 1\n",
    "        if row_unit['zipInconsistent'] == 1:  # added for zip codes\n",
    "            new_unit_df.at[idx_unit, 'zip_geometry'] = 'Wrong'\n",
    "            wrong_counts['zip_geometry'] += 1\n",
    "\n",
    "# Print the 'Wrong' counts\n",
    "for category, count in wrong_counts.items():\n",
    "    print(f\"{category}: {count} 'Wrong' values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
