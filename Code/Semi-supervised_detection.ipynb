{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb49b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "#Packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', None)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc75d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('Datasets/july_16_flood_data.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902eeac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2495293"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a304790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>agricultureStructureIndicator</th>\n",
       "      <th>asOfDate</th>\n",
       "      <th>policyCount</th>\n",
       "      <th>dateOfLoss</th>\n",
       "      <th>elevatedBuildingIndicator</th>\n",
       "      <th>ratedFloodZone</th>\n",
       "      <th>houseWorship</th>\n",
       "      <th>locationOfContents</th>\n",
       "      <th>numberOfFloorsInTheInsuredBuilding</th>\n",
       "      <th>nonProfitIndicator</th>\n",
       "      <th>occupancyType</th>\n",
       "      <th>originalConstructionDate</th>\n",
       "      <th>originalNBDate</th>\n",
       "      <th>amountPaidOnBuildingClaim</th>\n",
       "      <th>amountPaidOnContentsClaim</th>\n",
       "      <th>amountPaidOnIncreasedCostOfComplianceClaim</th>\n",
       "      <th>postFIRMConstructionIndicator</th>\n",
       "      <th>rateMethod</th>\n",
       "      <th>smallBusinessIndicatorBuilding</th>\n",
       "      <th>totalBuildingInsuranceCoverage</th>\n",
       "      <th>totalContentsInsuranceCoverage</th>\n",
       "      <th>yearOfLoss</th>\n",
       "      <th>primaryResidenceIndicator</th>\n",
       "      <th>buildingDamageAmount</th>\n",
       "      <th>buildingDeductibleCode</th>\n",
       "      <th>netBuildingPaymentAmount</th>\n",
       "      <th>buildingPropertyValue</th>\n",
       "      <th>causeOfDamage</th>\n",
       "      <th>condominiumCoverageTypeCode</th>\n",
       "      <th>contentsDeductibleCode</th>\n",
       "      <th>netContentsPaymentAmount</th>\n",
       "      <th>disasterAssistanceCoverageRequired</th>\n",
       "      <th>ficoNumber</th>\n",
       "      <th>floodWaterDuration</th>\n",
       "      <th>floodproofedIndicator</th>\n",
       "      <th>floodEvent</th>\n",
       "      <th>iccCoverage</th>\n",
       "      <th>netIccPaymentAmount</th>\n",
       "      <th>nfipRatedCommunityNumber</th>\n",
       "      <th>nfipCommunityName</th>\n",
       "      <th>numberOfUnits</th>\n",
       "      <th>buildingReplacementCost</th>\n",
       "      <th>replacementCostBasis</th>\n",
       "      <th>stateOwnedIndicator</th>\n",
       "      <th>waterDepth</th>\n",
       "      <th>rentalPropertyIndicator</th>\n",
       "      <th>state</th>\n",
       "      <th>reportedCity</th>\n",
       "      <th>reportedZipCode</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>censusTract</th>\n",
       "      <th>censusBlockGroupFips</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>id</th>\n",
       "      <th>proportionLeqOne</th>\n",
       "      <th>proportionLeqTwo</th>\n",
       "      <th>proportionLeqThree</th>\n",
       "      <th>proportionLeqFour</th>\n",
       "      <th>proportionLeqFive</th>\n",
       "      <th>proportionLeqSix</th>\n",
       "      <th>medWaterDepth</th>\n",
       "      <th>p25WaterDepth</th>\n",
       "      <th>p75WaterDepth</th>\n",
       "      <th>p90WaterDepth</th>\n",
       "      <th>diffMedWaterDepth</th>\n",
       "      <th>diff90WaterDepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22T16:55:53.194Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-02-07 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1963-01-01T00:00:00.000Z</td>\n",
       "      <td>1997-01-11T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pineapple Express - Southern</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60294.0</td>\n",
       "      <td>OCEANSIDE, CITY OF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Currently Unavailable</td>\n",
       "      <td>92056.0</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>6.073019e+09</td>\n",
       "      <td>6.073019e+10</td>\n",
       "      <td>33.2</td>\n",
       "      <td>-117.3</td>\n",
       "      <td>23dcb0d8-3e61-45bf-899f-b951946ce2ff</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22T16:55:53.194Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-08-29 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1967-07-01T00:00:00.000Z</td>\n",
       "      <td>1990-07-12T00:00:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hurricane Katrina</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225203.0</td>\n",
       "      <td>NEW ORLEANS/ORLEANS PARISH*</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>LA</td>\n",
       "      <td>Currently Unavailable</td>\n",
       "      <td>70131.0</td>\n",
       "      <td>22071.0</td>\n",
       "      <td>2.207100e+10</td>\n",
       "      <td>2.207100e+11</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>55783cdd-ccbd-4b19-930b-072def248507</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22T16:55:53.194Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-09-28 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972-01-01T00:00:00.000Z</td>\n",
       "      <td>1997-07-24T00:00:00.000Z</td>\n",
       "      <td>8813.21</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8813.21</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hurricane Georges (Panhandle)</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120274.0</td>\n",
       "      <td>SANTA ROSA COUNTY *</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Currently Unavailable</td>\n",
       "      <td>32566.0</td>\n",
       "      <td>12113.0</td>\n",
       "      <td>1.211301e+10</td>\n",
       "      <td>1.211301e+11</td>\n",
       "      <td>30.4</td>\n",
       "      <td>-86.9</td>\n",
       "      <td>bfb5922b-1b21-4882-b1d4-b3825ff53e37</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-19T13:45:58.425Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1994-10-07 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-01-01T00:00:00.000Z</td>\n",
       "      <td>1993-10-01T00:00:00.000Z</td>\n",
       "      <td>2906.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>4428.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2906.00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450026.0</td>\n",
       "      <td>BEAUFORT, CITY OF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC</td>\n",
       "      <td>Currently Unavailable</td>\n",
       "      <td>29902.0</td>\n",
       "      <td>45013.0</td>\n",
       "      <td>4.501300e+10</td>\n",
       "      <td>4.501300e+11</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>c1cf6e00-1e6d-4493-93fc-eb430ef15495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-19T13:45:58.425Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1996-03-11 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1988-01-01T00:00:00.000Z</td>\n",
       "      <td>1996-01-11T00:00:00.000Z</td>\n",
       "      <td>3875.53</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>5252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3875.53</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125092.0</td>\n",
       "      <td>BREVARD COUNTY *</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Currently Unavailable</td>\n",
       "      <td>32940.0</td>\n",
       "      <td>12009.0</td>\n",
       "      <td>1.200906e+10</td>\n",
       "      <td>1.200906e+11</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>cad8334c-13f2-4837-bdcf-e09591197ff7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  agricultureStructureIndicator                  asOfDate  \\\n",
       "0           0                              0  2020-01-22T16:55:53.194Z   \n",
       "1           1                              0  2020-01-22T16:55:53.194Z   \n",
       "2           2                              0  2020-01-22T16:55:53.194Z   \n",
       "3           3                              0  2019-09-19T13:45:58.425Z   \n",
       "4           4                              0  2019-09-19T13:45:58.425Z   \n",
       "\n",
       "   policyCount                 dateOfLoss  elevatedBuildingIndicator  \\\n",
       "0            1  1998-02-07 00:00:00+00:00                          0   \n",
       "1            1  2005-08-29 00:00:00+00:00                          0   \n",
       "2            1  1998-09-28 00:00:00+00:00                          0   \n",
       "3            1  1994-10-07 00:00:00+00:00                          0   \n",
       "4            1  1996-03-11 00:00:00+00:00                          0   \n",
       "\n",
       "  ratedFloodZone  houseWorship  locationOfContents  \\\n",
       "0              X             0                 NaN   \n",
       "1              X             0                 NaN   \n",
       "2              X             0                 NaN   \n",
       "3              X             0                 NaN   \n",
       "4              X             0                 NaN   \n",
       "\n",
       "   numberOfFloorsInTheInsuredBuilding  nonProfitIndicator  occupancyType  \\\n",
       "0                                 4.0                   0            1.0   \n",
       "1                                 2.0                   0            1.0   \n",
       "2                                 1.0                   0            1.0   \n",
       "3                                 2.0                   0            1.0   \n",
       "4                                 1.0                   0            1.0   \n",
       "\n",
       "   originalConstructionDate            originalNBDate  \\\n",
       "0  1963-01-01T00:00:00.000Z  1997-01-11T00:00:00.000Z   \n",
       "1  1967-07-01T00:00:00.000Z  1990-07-12T00:00:00.000Z   \n",
       "2  1972-01-01T00:00:00.000Z  1997-07-24T00:00:00.000Z   \n",
       "3  1960-01-01T00:00:00.000Z  1993-10-01T00:00:00.000Z   \n",
       "4  1988-01-01T00:00:00.000Z  1996-01-11T00:00:00.000Z   \n",
       "\n",
       "   amountPaidOnBuildingClaim  amountPaidOnContentsClaim  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                    8813.21                     1720.0   \n",
       "3                    2906.00                        0.0   \n",
       "4                    3875.53                     1545.0   \n",
       "\n",
       "   amountPaidOnIncreasedCostOfComplianceClaim  postFIRMConstructionIndicator  \\\n",
       "0                                         NaN                              0   \n",
       "1                                         NaN                              0   \n",
       "2                                         0.0                              0   \n",
       "3                                         0.0                              0   \n",
       "4                                         0.0                              1   \n",
       "\n",
       "  rateMethod  smallBusinessIndicatorBuilding  totalBuildingInsuranceCoverage  \\\n",
       "0          7                               0                        200000.0   \n",
       "1          7                               0                        100000.0   \n",
       "2          1                               0                        100000.0   \n",
       "3          7                               0                        100000.0   \n",
       "4          7                               0                        100000.0   \n",
       "\n",
       "   totalContentsInsuranceCoverage  yearOfLoss  primaryResidenceIndicator  \\\n",
       "0                         50000.0        1998                          0   \n",
       "1                         40000.0        2005                          1   \n",
       "2                         50000.0        1998                          1   \n",
       "3                         25000.0        1994                          0   \n",
       "4                         25000.0        1996                          1   \n",
       "\n",
       "   buildingDamageAmount buildingDeductibleCode  netBuildingPaymentAmount  \\\n",
       "0                 382.0                      0                      0.00   \n",
       "1                   NaN                      0                      0.00   \n",
       "2                9313.0                      0                   8813.21   \n",
       "3                4428.0                      0                   2906.00   \n",
       "4                5252.0                      0                   3875.53   \n",
       "\n",
       "   buildingPropertyValue causeOfDamage condominiumCoverageTypeCode  \\\n",
       "0                  937.0             1                           N   \n",
       "1                    NaN             1                           N   \n",
       "2                80000.0             1                           N   \n",
       "3               100000.0             1                           N   \n",
       "4               100000.0             1                           N   \n",
       "\n",
       "  contentsDeductibleCode  netContentsPaymentAmount  \\\n",
       "0                      0                       0.0   \n",
       "1                      0                       0.0   \n",
       "2                      0                    1720.0   \n",
       "3                      0                       0.0   \n",
       "4                      0                    1545.0   \n",
       "\n",
       "   disasterAssistanceCoverageRequired  ficoNumber  floodWaterDuration  \\\n",
       "0                                 0.0       612.0                 0.0   \n",
       "1                                 0.0       654.0                 0.0   \n",
       "2                                 0.0       133.0                 0.0   \n",
       "3                                 0.0         NaN                 0.0   \n",
       "4                                 0.0         NaN                 0.0   \n",
       "\n",
       "   floodproofedIndicator                     floodEvent  iccCoverage  \\\n",
       "0                      0   Pineapple Express - Southern      15000.0   \n",
       "1                      0              Hurricane Katrina      30000.0   \n",
       "2                      0  Hurricane Georges (Panhandle)      15000.0   \n",
       "3                      0                           None          NaN   \n",
       "4                      0                           None          NaN   \n",
       "\n",
       "   netIccPaymentAmount  nfipRatedCommunityNumber            nfipCommunityName  \\\n",
       "0                  0.0                   60294.0           OCEANSIDE, CITY OF   \n",
       "1                  0.0                  225203.0  NEW ORLEANS/ORLEANS PARISH*   \n",
       "2                  0.0                  120274.0          SANTA ROSA COUNTY *   \n",
       "3                  0.0                  450026.0            BEAUFORT, CITY OF   \n",
       "4                  0.0                  125092.0             BREVARD COUNTY *   \n",
       "\n",
       "   numberOfUnits  buildingReplacementCost replacementCostBasis  \\\n",
       "0            1.0                    937.0                    A   \n",
       "1            1.0                      NaN                    A   \n",
       "2            1.0                 100000.0                    A   \n",
       "3            1.0                      0.0                    A   \n",
       "4            1.0                      0.0                    A   \n",
       "\n",
       "   stateOwnedIndicator  waterDepth  rentalPropertyIndicator state  \\\n",
       "0                    0         0.0                        0    CA   \n",
       "1                    0         0.0                        0    LA   \n",
       "2                    0         0.0                        0    FL   \n",
       "3                    0         0.0                        0    SC   \n",
       "4                    0         0.0                        0    FL   \n",
       "\n",
       "            reportedCity  reportedZipCode  countyCode   censusTract  \\\n",
       "0  Currently Unavailable          92056.0      6073.0  6.073019e+09   \n",
       "1  Currently Unavailable          70131.0     22071.0  2.207100e+10   \n",
       "2  Currently Unavailable          32566.0     12113.0  1.211301e+10   \n",
       "3  Currently Unavailable          29902.0     45013.0  4.501300e+10   \n",
       "4  Currently Unavailable          32940.0     12009.0  1.200906e+10   \n",
       "\n",
       "   censusBlockGroupFips  latitude  longitude  \\\n",
       "0          6.073019e+10      33.2     -117.3   \n",
       "1          2.207100e+11      29.9      -90.0   \n",
       "2          1.211301e+11      30.4      -86.9   \n",
       "3          4.501300e+11      32.4      -80.7   \n",
       "4          1.200906e+11      28.3      -80.7   \n",
       "\n",
       "                                     id  proportionLeqOne  proportionLeqTwo  \\\n",
       "0  23dcb0d8-3e61-45bf-899f-b951946ce2ff          1.000000          1.000000   \n",
       "1  55783cdd-ccbd-4b19-930b-072def248507          0.928571          0.939560   \n",
       "2  bfb5922b-1b21-4882-b1d4-b3825ff53e37          0.888889          0.888889   \n",
       "3  c1cf6e00-1e6d-4493-93fc-eb430ef15495          1.000000          1.000000   \n",
       "4  cad8334c-13f2-4837-bdcf-e09591197ff7          1.000000          1.000000   \n",
       "\n",
       "   proportionLeqThree  proportionLeqFour  proportionLeqFive  proportionLeqSix  \\\n",
       "0            1.000000           1.000000           1.000000          1.000000   \n",
       "1            0.939560           0.939560           0.950549          0.950549   \n",
       "2            0.888889           0.888889           1.000000          1.000000   \n",
       "3            1.000000           1.000000           1.000000          1.000000   \n",
       "4            1.000000           1.000000           1.000000          1.000000   \n",
       "\n",
       "   medWaterDepth  p25WaterDepth  p75WaterDepth  p90WaterDepth  \\\n",
       "0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            1.0            1.0   \n",
       "2            0.0            0.0            0.0            1.0   \n",
       "3            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   diffMedWaterDepth  diff90WaterDepth  \n",
       "0                0.0               0.0  \n",
       "1                0.0              -1.0  \n",
       "2                0.0              -1.0  \n",
       "3                0.0               0.0  \n",
       "4                0.0               0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80944e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['floodEvent']!='Hurricane Katrina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a18da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['buildingPropertyValue'] >= 10000) & (df['buildingPropertyValue'] < 10000000)]\n",
    "\n",
    "df = df[df['medWaterDepth'] < 20]\n",
    "\n",
    "df['relativeDamage'] = df['buildingDamageAmount']/df['buildingPropertyValue']\n",
    "\n",
    "df['relativeDamage'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df = df[df['relativeDamage'] <= 1]\n",
    "\n",
    "df['dateOfLoss'] = pd.to_datetime(df['dateOfLoss'])\n",
    "df['originalConstructionDate'] = pd.to_datetime(df['originalConstructionDate'], errors='coerce')\n",
    "df['originalConstructionDate_year'] = df['originalConstructionDate'].dt.year\n",
    "\n",
    "df['AgeofBuildinguntilflood'] = df['yearOfLoss'] - df['originalConstructionDate_year']\n",
    "\n",
    "df = df[df['AgeofBuildinguntilflood']>=0]\n",
    "\n",
    "df['bool95'] = df['proportionLeqOne'] >= .95\n",
    "df['bool90'] = df['proportionLeqOne'] >= .9\n",
    "df['bool80'] = df['proportionLeqOne'] >= .8\n",
    "df['bool75'] = df['proportionLeqOne'] >= .75\n",
    "df['bool50'] = df['proportionLeqOne'] >= .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5fb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bool0'] = (df['proportionLeqOne'] <= .2) \n",
    "df['bool1'] = (df['proportionLeqOne'] > .2) & (df['proportionLeqOne'] <= .4)\n",
    "df['bool2'] = (df['proportionLeqOne'] > .4) & (df['proportionLeqOne'] <= .6)\n",
    "df['bool3'] = (df['proportionLeqOne'] > .6) & (df['proportionLeqOne'] <= .8)\n",
    "df['bool4'] = (df['proportionLeqOne'] > .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc92679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame and 'elevationDifference' is the column name\n",
    "\n",
    "# # Step 1: Impute missing values with mean imputation\n",
    "# mean_imputation = df['elevationDifference'].mean()\n",
    "# df['elevationDifference'] = df['elevationDifference'].fillna(mean_imputation)\n",
    "\n",
    "# # Step 2: Remove outliers\n",
    "# z_scores = np.abs((df['elevationDifference'] - df['elevationDifference'].mean()) / df['elevationDifference'].std())\n",
    "# threshold = 3  # Adjust the threshold as needed\n",
    "# df = df[z_scores <= threshold]\n",
    "\n",
    "# # Step 3: Create categorical bins\n",
    "# num_bins = 10\n",
    "# df['elevationDifference_category'] = pd.cut(df['elevationDifference'], bins=num_bins, labels=False)\n",
    "\n",
    "# # Optional: Rename the categories to meaningful labels\n",
    "# category_labels = ['Category 1', 'Category 2', 'Category 3', 'Category 4', 'Category 5',\n",
    "#                    'Category 6', 'Category 7', 'Category 8', 'Category 9', 'Category 10']\n",
    "# df['elevationDifference_category'] = df['elevationDifference_category'].map(lambda x: category_labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_variables = ['waterDepth', 'floodEvent', 'ratedFloodZone', \n",
    "#                      'causeOfDamage', 'yearOfLoss', 'state',  'relativeDamage',\n",
    "#                      'AgeofBuildinguntilflood',\n",
    "#                      'postFIRMConstructionIndicator', 'occupancyType' , \n",
    "#                      'floodproofedIndicator', 'rateMethod', 'proportionLeqOne', \n",
    "#                      'bool75', 'bool50', 'bool80', 'bool90', 'medWaterDepth']\n",
    "\n",
    "\n",
    "desired_variables = ['elevatedBuildingIndicator', 'numberOfFloorsInTheInsuredBuilding', 'occupancyType', \n",
    "                     'postFIRMConstructionIndicator', \n",
    "                     'yearOfLoss', 'causeOfDamage', 'floodproofedIndicator', \n",
    "                     'proportionLeqOne', 'relativeDamage',\n",
    "                     'AgeofBuildinguntilflood', 'bool0', 'bool1', 'bool2', 'bool3', 'bool4', \n",
    "                     'proportionLeqTwo', 'proportionLeqThree','p90WaterDepth', 'AgeofBuildinguntilflood']\n",
    "\n",
    "df_new = df[desired_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fce9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the variables to one-hot encode\n",
    "variables_to_encode = ['numberOfFloorsInTheInsuredBuilding',  'occupancyType', \n",
    "                       'causeOfDamage', 'yearOfLoss']\n",
    "\n",
    "# variables_to_encode = ['floodEvent', 'ratedFloodZone', \n",
    "#                        'causeOfDamage', 'state', 'yearOfLoss', \n",
    "#                        'occupancyType', 'floodproofedIndicator', 'rateMethod']\n",
    "\n",
    "#variables excluding: smallBusinessIndicatorBuilding', 'buildingDamageAmount', ,'stateOwnedIndicator', 'rateMethod', 'rentalPropertyIndicator' , floodWaterDuration \n",
    "#, 'p75WaterDepth',  'p90WaterDepth','diff90WaterDepth' 'proportionLeqTwo',\n",
    "      # 'proportionLeqThree', 'proportionLeqFour', 'proportionLeqFive',\n",
    "      # 'proportionLeqSix','p25WaterDepth', 'originalConstructionDateYear',  'diffMedWaterDepth', 'medWaterDepth'\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_new, columns=variables_to_encode)\n",
    "\n",
    "# Include the non-one-hot encoded variables from the original dataframe\n",
    "# variables_to_include = ['waterDepth', 'AgeofBuildinguntilflood',   'postFIRMConstructionIndicator', 'relativeDamage', 'proportionLeqOne',  'bool75', 'bool50', 'bool80', 'bool90', 'medWaterDepth']\n",
    "# variables_to_include = ['waterDepth', 'AgeofBuildinguntilflood',   'postFIRMConstructionIndicator', 'relativeDamage', 'bool75', 'bool50', 'bool80', 'bool90', 'medWaterDepth']\n",
    "\n",
    "variables_to_include = ['elevatedBuildingIndicator', 'postFIRMConstructionIndicator',\n",
    "                       'floodproofedIndicator','proportionLeqOne', 'relativeDamage',\n",
    "                     'AgeofBuildinguntilflood', 'bool0', 'bool1', 'bool2', 'bool3', 'bool4', \n",
    "                     'proportionLeqTwo', 'proportionLeqThree','p90WaterDepth', 'AgeofBuildinguntilflood']\n",
    "\n",
    "df_encoded[variables_to_include] = df_encoded[variables_to_include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b189f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Specify the variables to normalize\n",
    "variables_to_normalize = ['AgeofBuildinguntilflood', 'relativeDamage', 'proportionLeqOne',  'medWaterDepth']\n",
    "# variables_to_normalize = ['AgeofBuildinguntilflood', 'relativeDamage',  'medWaterDepth']\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the variables\n",
    "df_encoded[variables_to_normalize] = scaler.fit_transform(df_encoded[variables_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7cfc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_6ft = df_copy[df_copy['waterDepth']==6].copy()\n",
    "df_copy_6ft.drop(['waterDepth'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a23c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_inches = df_encoded[(df_encoded['waterDepth'] == 1) | (df_encoded['waterDepth'] == 0)].copy()\n",
    "df_train_feet = df_encoded[(df_encoded['waterDepth'] == 5) | (df_encoded['waterDepth'] == 7)].copy()\n",
    "df_6ft = df_encoded[df_encoded['waterDepth'] == 6].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_inches.drop(['waterDepth'], axis=1, inplace=True)\n",
    "df_train_feet.drop(['waterDepth'], axis=1, inplace=True)\n",
    "df_6ft.drop(['waterDepth'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_6ft.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6ft.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb92fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_inches = df_train_inches.sample(n=1600, random_state=42)\n",
    "\n",
    "df_train_feet = df_train_feet.sample(n=8000, random_state=42)\n",
    "\n",
    "df_train_inches = df_train_inches.reset_index().drop(columns='index')\n",
    "df_train_feet = df_train_feet.reset_index().drop(columns='index')\n",
    "\n",
    "y_inches = np.ones(df_train_inches.shape[0], dtype=int)\n",
    "y_feet = np.zeros(df_train_feet.shape[0], dtype=int)\n",
    "\n",
    "# Concatenate df_train_inches and df_train_feet into df_train\n",
    "df_train = pd.concat([df_train_inches, df_train_feet])\n",
    "\n",
    "# Concatenate y_inches and y_feet into y\n",
    "y = np.concatenate([y_inches, y_feet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f040c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ed621",
   "metadata": {},
   "source": [
    "### XGBOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf221d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "iforest = IForest()\n",
    "hbos = HBOS()\n",
    "knn = KNN()\n",
    "\n",
    "# xgbod = XGBOD(random_state=42, estimator_list=[iforest, hbos, knn], max_depth = 4, base_score = 0.2)\n",
    "\n",
    "xgbod = XGBOD(random_state=42, estimator_list=[iforest, hbos, knn], max_depth = 4, gamma = 0.2, reg_alpha = 0.1,\n",
    "              reg_lambda = 0.9, base_score = 0.2)\n",
    "xgbod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = xgbod.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = xgbod.decision_scores_  # raw outlier scores\n",
    "y_train_scores = xgbod.decision_function(X_train)\n",
    "# get the prediction on the test data\n",
    "y_test_pred = xgbod.predict(X_test)  # outlier labels (0 or 1)\n",
    "y_test_scores = xgbod.decision_function(X_test)  # outlier scores\n",
    "\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "print(\"The training data:\", count_stat(y_train_pred))\n",
    "print(\"The test data:\", count_stat(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f74652",
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual_pred = pd.DataFrame({'Actual': y_test, 'Pred': y_test_pred})\n",
    "pd.crosstab(Actual_pred['Actual'],Actual_pred['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new = pd.DataFrame(X_train)\n",
    "df_columns = df_train_new.columns\n",
    "df_train_new['pred'] = y_train_pred\n",
    "df_train_new['Group'] = np.where(df_train_new['pred']==1, 'Outlier','Normal')\n",
    "\n",
    "# Now let's show the summary statistics:\n",
    "cnt = df_train_new.groupby('Group')['pred'].count().reset_index().rename(columns={'pred':'Count'})\n",
    "cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "stat = df_train_new.groupby('Group').mean().reset_index() # The avg.\n",
    "cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6481be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction on the 6ft data\n",
    "y_6ft_pred = xgbod.predict(df_6ft)  # outlier labels (0 or 1)\n",
    "y_6ft_scores = xgbod.decision_function(df_6ft)  # outlier scores\n",
    "\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "print(\"The test data:\", count_stat(y_6ft_pred))\n",
    "print(y_6ft_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01df3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_6ft_pred == 1\n",
    "\n",
    "mask_inliers = y_6ft_pred == 0\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "filtered_df = df_copy_6ft[mask]\n",
    "\n",
    "filtered_df_inliers = df_copy_6ft[mask_inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['relativeDamage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ed02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['proportionLeqOne'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_inliers['relativeDamage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_6ft['relativeDamage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b584ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_6ft['proportionLeqOne'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bins and the bin edges\n",
    "\n",
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "filtered_df['bins'] = pd.cut(filtered_df['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = filtered_df.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "    \n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bins and the bin edges\n",
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "filtered_df_inliers['bins'] = pd.cut(filtered_df_inliers['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = filtered_df_inliers.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "    \n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab35e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_1ft_encoded = df_encoded[(df_encoded['waterDepth'] == 1) | (df_encoded['waterDepth'] == 0)].copy()\n",
    "df_copy_1ft_encoded.drop(['waterDepth'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_copy_1ft_encoded = df_copy_1ft_encoded.sample(n=10000, random_state=42)\n",
    "\n",
    "df_copy_1ft_copy = df_copy_1ft_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the variables to normalize\n",
    "# variables_to_normalize = ['AgeofBuildinguntilflood', 'relativeDamage', 'proportionLeqOne',  'medWaterDepth']\n",
    "variables_to_normalize = ['AgeofBuildinguntilflood', 'relativeDamage',  'medWaterDepth']\n",
    "\n",
    "# Normalize the variables\n",
    "df_copy_1ft_copy[variables_to_normalize] = scaler.transform(df_copy_1ft_copy[variables_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67549b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = xgbod.predict(df_copy_1ft_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.count_nonzero(y_train_pred == 1)/10000)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eff7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_train_pred == 1\n",
    "\n",
    "mask_inliers = y_train_pred == 0\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "filtered_df = df_copy_1ft_encoded[mask]\n",
    "\n",
    "filtered_df_inliers = df_copy_1ft_encoded[mask_inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "filtered_df['bins'] = pd.cut(filtered_df['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = filtered_df.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "\n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "df_copy_1ft_encoded['bins'] = pd.cut(df_copy_1ft_encoded['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = df_copy_1ft_encoded.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "\n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e00daa",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a842d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "atcdr = AutoEncoder(contamination=0.1, hidden_neurons =[256, 128, 64, 32, 64, 128, 256])\n",
    "atcdr.fit(df_6ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83295e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scores = atcdr.decision_function(df_6ft)\n",
    "y_train_pred = atcdr.predict(df_6ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51613d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Threshold for the defined comtanimation rate\n",
    "print(\"The threshold for the defined contamination rate:\" , atcdr.threshold_)\n",
    "\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "print(\"The training data:\", count_stat(y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01099fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_scores, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Outlier score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = atcdr.threshold_ # Or other value from the above histogram\n",
    "\n",
    "def descriptive_stat_threshold(df,pred_score, threshold):\n",
    "    # Let's see how many '0's and '1's.\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
    "\n",
    "    # Now let's show the summary statistics:\n",
    "    cnt = df_6ft.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
    "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
    "    return (stat)\n",
    "\n",
    "descriptive_stat_threshold(df_6ft,y_train_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_train_pred == 1\n",
    "\n",
    "mask_inliers = y_train_pred == 0\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "filtered_df = df_copy_6ft[mask]\n",
    "\n",
    "filtered_df_inliers = df_copy_6ft[mask_inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22630cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['relativeDamage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['proportionLeqOne'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_inliers['relativeDamage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_6ft['relativeDamage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af60a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_6ft['proportionLeqOne'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08046607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "filtered_df['bins'] = pd.cut(filtered_df['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = filtered_df.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "\n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "filtered_df_inliers['bins'] = pd.cut(filtered_df_inliers['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = filtered_df_inliers.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "\n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ee748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_1ft_encoded = df_encoded[(df_encoded['waterDepth'] == 1) | (df_encoded['waterDepth'] == 0)].copy()\n",
    "df_copy_1ft_encoded.drop(['waterDepth'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_copy_1ft_encoded = df_copy_1ft_encoded.sample(n=10000, random_state=42)\n",
    "\n",
    "df_copy_1ft_copy = df_copy_1ft_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Specify the variables to normalize\n",
    "variables_to_normalize = ['AgeofBuildinguntilflood', 'relativeDamage', 'proportionLeqOne',  'medWaterDepth']\n",
    "\n",
    "# Normalize the variables\n",
    "df_copy_1ft_copy[variables_to_normalize] = scaler.transform(df_copy_1ft_copy[variables_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46002a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = atcdr.predict(df_copy_1ft_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(y_train_pred == 1)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b79d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_train_pred == 1\n",
    "\n",
    "mask_inliers = y_train_pred == 0\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "filtered_df = df_copy_1ft_encoded[mask]\n",
    "\n",
    "filtered_df_inliers = df_copy_1ft_encoded[mask_inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf74d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_inliers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec54d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "filtered_df['bins'] = pd.cut(filtered_df['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = filtered_df.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "\n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa013bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bin_edges = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Cut the data into bins\n",
    "df_copy_1ft_encoded['bins'] = pd.cut(df_copy_1ft_encoded['proportionLeqOne'], bins=bin_edges)\n",
    "\n",
    "# Group the data by the bins\n",
    "grouped_data = df_copy_1ft_encoded.groupby('bins')\n",
    "\n",
    "# Create a figure and axis for the boxplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the positions of each boxplot\n",
    "positions = []\n",
    "\n",
    "# Store the labels for the bins\n",
    "bin_labels = []\n",
    "\n",
    "# Iterate over the groups and create boxplots\n",
    "for i, (group, data) in enumerate(grouped_data):\n",
    "    positions.append(i+1)\n",
    "    # count the number of observations in the bin\n",
    "    num_observations = len(data)\n",
    "    # create the label for the bin\n",
    "    bin_label = f'{group.left:.1f} to {group.right:.1f}'\n",
    "    bin_labels.append(bin_label)\n",
    "    ax.boxplot(data['relativeDamage'], positions=[i+1])\n",
    "\n",
    "    # Annotate number of observations at the very top of the figure\n",
    "    ax.text(i+1, 1.05, f'n={num_observations}', ha='center', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Set the x-axis labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(bin_labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Bins of proportionLeqOne')\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Relative Damage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb7bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ef200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43cd92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac940b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206215b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "atcdr1 = AutoEncoder(contamination=0.05, hidden_neurons =[2, 2])\n",
    "atcdr2 = AutoEncoder(contamination=0.05, hidden_neurons =[10, 2, 10])\n",
    "atcdr3 = AutoEncoder(contamination=0.05, hidden_neurons =[15, 10, 2, 10, 15] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8548cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "atcdr1.fit(df_6ft)\n",
    "atcdr2.fit(df_6ft)\n",
    "atcdr3.fit(df_6ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a66eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in each column:\n",
    "train_scores[:, 0] = atcdr1.decision_function(df_6ft) \n",
    "train_scores[:, 1] = atcdr2.decision_function(df_6ft) \n",
    "train_scores[:, 2] = atcdr3.decision_function(df_6ft)\n",
    "test_scores[:, 0] = atcdr1.decision_function(df_6ft) \n",
    "test_scores[:, 1] = atcdr2.decision_function(df_6ft) \n",
    "test_scores[:, 2] = atcdr3.decision_function(df_6ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae15d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision scores have to be normalized before combination\n",
    "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)\n",
    "\n",
    "# Combination by average\n",
    "y_train_by_average = average(train_scores_norm)\n",
    "y_test_by_average = average(test_scores_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_by_average, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Combination by average\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3da2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stat_threshold(X_train,y_train_by_average, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab1ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37071763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44816466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c439841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
